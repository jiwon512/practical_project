{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34629d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf0fb06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/Jiwon/Documents/GitHub/practical_project/csv/test.csv\", encoding=\"cp949\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ced1b6f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>농장아이디</th>\n",
       "      <th>개체번호</th>\n",
       "      <th>착유량</th>\n",
       "      <th>착유시작일시</th>\n",
       "      <th>착유종료일시</th>\n",
       "      <th>착유회차</th>\n",
       "      <th>전도도</th>\n",
       "      <th>혈액흐름</th>\n",
       "      <th>온도</th>\n",
       "      <th>유지방</th>\n",
       "      <th>유단백</th>\n",
       "      <th>공기흐름</th>\n",
       "      <th>착유시간</th>\n",
       "      <th>나이</th>\n",
       "      <th>측정일</th>\n",
       "      <th>개체별 일일착유량</th>\n",
       "      <th>개체별 착유일수</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20278</td>\n",
       "      <td>20130816010079</td>\n",
       "      <td>16</td>\n",
       "      <td>2021-09-01 06:52:00</td>\n",
       "      <td>2021-09-01 07:04:00</td>\n",
       "      <td>1</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0</td>\n",
       "      <td>39.9</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20278</td>\n",
       "      <td>20130816010079</td>\n",
       "      <td>17</td>\n",
       "      <td>2021-09-01 17:02:00</td>\n",
       "      <td>2021-09-01 17:11:00</td>\n",
       "      <td>2</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0</td>\n",
       "      <td>40.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20278</td>\n",
       "      <td>20130816010079</td>\n",
       "      <td>14</td>\n",
       "      <td>2021-09-02 01:41:00</td>\n",
       "      <td>2021-09-02 01:51:00</td>\n",
       "      <td>1</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0</td>\n",
       "      <td>39.9</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20278</td>\n",
       "      <td>20130816010079</td>\n",
       "      <td>10</td>\n",
       "      <td>2021-09-02 07:28:00</td>\n",
       "      <td>2021-09-02 07:36:00</td>\n",
       "      <td>2</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0</td>\n",
       "      <td>39.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20278</td>\n",
       "      <td>20130816010079</td>\n",
       "      <td>11</td>\n",
       "      <td>2021-09-02 14:33:00</td>\n",
       "      <td>2021-09-02 14:45:00</td>\n",
       "      <td>3</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21653</th>\n",
       "      <td>20264</td>\n",
       "      <td>20191027020116</td>\n",
       "      <td>9</td>\n",
       "      <td>2021-09-25 01:29:00</td>\n",
       "      <td>2021-09-25 01:35:00</td>\n",
       "      <td>1</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0</td>\n",
       "      <td>38.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>29</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21654</th>\n",
       "      <td>20264</td>\n",
       "      <td>20191027020116</td>\n",
       "      <td>9</td>\n",
       "      <td>2021-09-25 09:15:00</td>\n",
       "      <td>2021-09-25 09:21:00</td>\n",
       "      <td>2</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0</td>\n",
       "      <td>39.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>29</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21655</th>\n",
       "      <td>20264</td>\n",
       "      <td>20191027020116</td>\n",
       "      <td>11</td>\n",
       "      <td>2021-09-25 19:28:00</td>\n",
       "      <td>2021-09-25 19:35:00</td>\n",
       "      <td>3</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0</td>\n",
       "      <td>39.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>29</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21656</th>\n",
       "      <td>20264</td>\n",
       "      <td>20191027020116</td>\n",
       "      <td>13</td>\n",
       "      <td>2021-09-26 08:22:00</td>\n",
       "      <td>2021-09-26 08:29:00</td>\n",
       "      <td>1</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0</td>\n",
       "      <td>39.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21657</th>\n",
       "      <td>20264</td>\n",
       "      <td>20191027020116</td>\n",
       "      <td>13</td>\n",
       "      <td>2021-09-26 19:42:00</td>\n",
       "      <td>2021-09-26 19:49:00</td>\n",
       "      <td>2</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0</td>\n",
       "      <td>39.6</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21658 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       농장아이디            개체번호  착유량               착유시작일시               착유종료일시  \\\n",
       "0      20278  20130816010079   16  2021-09-01 06:52:00  2021-09-01 07:04:00   \n",
       "1      20278  20130816010079   17  2021-09-01 17:02:00  2021-09-01 17:11:00   \n",
       "2      20278  20130816010079   14  2021-09-02 01:41:00  2021-09-02 01:51:00   \n",
       "3      20278  20130816010079   10  2021-09-02 07:28:00  2021-09-02 07:36:00   \n",
       "4      20278  20130816010079   11  2021-09-02 14:33:00  2021-09-02 14:45:00   \n",
       "...      ...             ...  ...                  ...                  ...   \n",
       "21653  20264  20191027020116    9  2021-09-25 01:29:00  2021-09-25 01:35:00   \n",
       "21654  20264  20191027020116    9  2021-09-25 09:15:00  2021-09-25 09:21:00   \n",
       "21655  20264  20191027020116   11  2021-09-25 19:28:00  2021-09-25 19:35:00   \n",
       "21656  20264  20191027020116   13  2021-09-26 08:22:00  2021-09-26 08:29:00   \n",
       "21657  20264  20191027020116   13  2021-09-26 19:42:00  2021-09-26 19:49:00   \n",
       "\n",
       "       착유회차  전도도  혈액흐름    온도  유지방  유단백  공기흐름  착유시간  나이  측정일  개체별 일일착유량  \\\n",
       "0         1  7.1     0  39.9  4.1  3.3   1.5  12.0   8    1         33   \n",
       "1         2  6.8     0  40.2  4.5  3.2   2.1   9.0   8    1         33   \n",
       "2         1  6.8     0  39.9  4.8  3.1   1.9  10.0   8    2         35   \n",
       "3         2  6.8     0  39.6  5.0  3.1   1.7   8.0   8    2         35   \n",
       "4         3  6.8     0  40.0  4.7  3.2   1.3  12.0   8    2         35   \n",
       "...     ...  ...   ...   ...  ...  ...   ...   ...  ..  ...        ...   \n",
       "21653     1  6.2     0  38.8  3.3  3.3   3.7   6.0   1   25         29   \n",
       "21654     2  6.4     0  39.2  2.8  3.3   3.7   6.0   1   25         29   \n",
       "21655     3  6.4     0  39.5  2.5  3.4   3.9   7.0   1   25         29   \n",
       "21656     1  6.2     0  39.4  2.8  3.4   4.0   7.0   1   26         26   \n",
       "21657     2  6.4     0  39.6  2.5  3.4   3.7   7.0   1   26         26   \n",
       "\n",
       "       개체별 착유일수  \n",
       "0            26  \n",
       "1            26  \n",
       "2            26  \n",
       "3            26  \n",
       "4            26  \n",
       "...         ...  \n",
       "21653        19  \n",
       "21654        19  \n",
       "21655        19  \n",
       "21656        19  \n",
       "21657        19  \n",
       "\n",
       "[21658 rows x 17 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a492bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_cols = ['착유시작일시', '착유종료일시']\n",
    "for c in date_cols:\n",
    "    df[c] = pd.to_datetime(df[c], errors='coerce')  # coerce will turn bad parses into NaT\n",
    "\n",
    "# now you can safely do:\n",
    "df['착유시간대']   = df['착유시작일시'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7707a92e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>농장아이디</th>\n",
       "      <th>개체번호</th>\n",
       "      <th>착유량</th>\n",
       "      <th>착유시작일시</th>\n",
       "      <th>착유종료일시</th>\n",
       "      <th>착유회차</th>\n",
       "      <th>전도도</th>\n",
       "      <th>혈액흐름</th>\n",
       "      <th>온도</th>\n",
       "      <th>유지방</th>\n",
       "      <th>유단백</th>\n",
       "      <th>공기흐름</th>\n",
       "      <th>착유시간</th>\n",
       "      <th>나이</th>\n",
       "      <th>측정일</th>\n",
       "      <th>개체별 일일착유량</th>\n",
       "      <th>개체별 착유일수</th>\n",
       "      <th>착유시간대</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20278</td>\n",
       "      <td>20130816010079</td>\n",
       "      <td>16</td>\n",
       "      <td>2021-09-01 06:52:00</td>\n",
       "      <td>2021-09-01 07:04:00</td>\n",
       "      <td>1</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0</td>\n",
       "      <td>39.9</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20278</td>\n",
       "      <td>20130816010079</td>\n",
       "      <td>17</td>\n",
       "      <td>2021-09-01 17:02:00</td>\n",
       "      <td>2021-09-01 17:11:00</td>\n",
       "      <td>2</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0</td>\n",
       "      <td>40.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>26</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20278</td>\n",
       "      <td>20130816010079</td>\n",
       "      <td>14</td>\n",
       "      <td>2021-09-02 01:41:00</td>\n",
       "      <td>2021-09-02 01:51:00</td>\n",
       "      <td>1</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0</td>\n",
       "      <td>39.9</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20278</td>\n",
       "      <td>20130816010079</td>\n",
       "      <td>10</td>\n",
       "      <td>2021-09-02 07:28:00</td>\n",
       "      <td>2021-09-02 07:36:00</td>\n",
       "      <td>2</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0</td>\n",
       "      <td>39.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20278</td>\n",
       "      <td>20130816010079</td>\n",
       "      <td>11</td>\n",
       "      <td>2021-09-02 14:33:00</td>\n",
       "      <td>2021-09-02 14:45:00</td>\n",
       "      <td>3</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>26</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21653</th>\n",
       "      <td>20264</td>\n",
       "      <td>20191027020116</td>\n",
       "      <td>9</td>\n",
       "      <td>2021-09-25 01:29:00</td>\n",
       "      <td>2021-09-25 01:35:00</td>\n",
       "      <td>1</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0</td>\n",
       "      <td>38.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>29</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21654</th>\n",
       "      <td>20264</td>\n",
       "      <td>20191027020116</td>\n",
       "      <td>9</td>\n",
       "      <td>2021-09-25 09:15:00</td>\n",
       "      <td>2021-09-25 09:21:00</td>\n",
       "      <td>2</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0</td>\n",
       "      <td>39.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>29</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21655</th>\n",
       "      <td>20264</td>\n",
       "      <td>20191027020116</td>\n",
       "      <td>11</td>\n",
       "      <td>2021-09-25 19:28:00</td>\n",
       "      <td>2021-09-25 19:35:00</td>\n",
       "      <td>3</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0</td>\n",
       "      <td>39.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>29</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21656</th>\n",
       "      <td>20264</td>\n",
       "      <td>20191027020116</td>\n",
       "      <td>13</td>\n",
       "      <td>2021-09-26 08:22:00</td>\n",
       "      <td>2021-09-26 08:29:00</td>\n",
       "      <td>1</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0</td>\n",
       "      <td>39.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21657</th>\n",
       "      <td>20264</td>\n",
       "      <td>20191027020116</td>\n",
       "      <td>13</td>\n",
       "      <td>2021-09-26 19:42:00</td>\n",
       "      <td>2021-09-26 19:49:00</td>\n",
       "      <td>2</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0</td>\n",
       "      <td>39.6</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21658 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       농장아이디            개체번호  착유량              착유시작일시              착유종료일시  \\\n",
       "0      20278  20130816010079   16 2021-09-01 06:52:00 2021-09-01 07:04:00   \n",
       "1      20278  20130816010079   17 2021-09-01 17:02:00 2021-09-01 17:11:00   \n",
       "2      20278  20130816010079   14 2021-09-02 01:41:00 2021-09-02 01:51:00   \n",
       "3      20278  20130816010079   10 2021-09-02 07:28:00 2021-09-02 07:36:00   \n",
       "4      20278  20130816010079   11 2021-09-02 14:33:00 2021-09-02 14:45:00   \n",
       "...      ...             ...  ...                 ...                 ...   \n",
       "21653  20264  20191027020116    9 2021-09-25 01:29:00 2021-09-25 01:35:00   \n",
       "21654  20264  20191027020116    9 2021-09-25 09:15:00 2021-09-25 09:21:00   \n",
       "21655  20264  20191027020116   11 2021-09-25 19:28:00 2021-09-25 19:35:00   \n",
       "21656  20264  20191027020116   13 2021-09-26 08:22:00 2021-09-26 08:29:00   \n",
       "21657  20264  20191027020116   13 2021-09-26 19:42:00 2021-09-26 19:49:00   \n",
       "\n",
       "       착유회차  전도도  혈액흐름    온도  유지방  유단백  공기흐름  착유시간  나이  측정일  개체별 일일착유량  \\\n",
       "0         1  7.1     0  39.9  4.1  3.3   1.5  12.0   8    1         33   \n",
       "1         2  6.8     0  40.2  4.5  3.2   2.1   9.0   8    1         33   \n",
       "2         1  6.8     0  39.9  4.8  3.1   1.9  10.0   8    2         35   \n",
       "3         2  6.8     0  39.6  5.0  3.1   1.7   8.0   8    2         35   \n",
       "4         3  6.8     0  40.0  4.7  3.2   1.3  12.0   8    2         35   \n",
       "...     ...  ...   ...   ...  ...  ...   ...   ...  ..  ...        ...   \n",
       "21653     1  6.2     0  38.8  3.3  3.3   3.7   6.0   1   25         29   \n",
       "21654     2  6.4     0  39.2  2.8  3.3   3.7   6.0   1   25         29   \n",
       "21655     3  6.4     0  39.5  2.5  3.4   3.9   7.0   1   25         29   \n",
       "21656     1  6.2     0  39.4  2.8  3.4   4.0   7.0   1   26         26   \n",
       "21657     2  6.4     0  39.6  2.5  3.4   3.7   7.0   1   26         26   \n",
       "\n",
       "       개체별 착유일수  착유시간대  \n",
       "0            26      6  \n",
       "1            26     17  \n",
       "2            26      1  \n",
       "3            26      7  \n",
       "4            26     14  \n",
       "...         ...    ...  \n",
       "21653        19      1  \n",
       "21654        19      9  \n",
       "21655        19     19  \n",
       "21656        19      8  \n",
       "21657        19     19  \n",
       "\n",
       "[21658 rows x 18 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed3089cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int8\n"
     ]
    }
   ],
   "source": [
    "# 착유 시간대 구분\n",
    "\n",
    "# 1) cut 으로 4구간 나눈 뒤\n",
    "df['착유시간대'] = pd.cut(\n",
    "    df['착유시간대'],\n",
    "    bins=[0,6,12,18,24],\n",
    "    right=False,\n",
    "    labels=[1,2,3,4]\n",
    ")\n",
    "\n",
    "# 2) category → 정수로 변환\n",
    "df['착유시간대'] = df['착유시간대'].cat.codes + 1  \n",
    "# (codes가 0~3 이므로 +1 하면 원래 라벨 1~4가 됨)\n",
    "\n",
    "# 3) 이제 dtype 확인해 보면 int64 로 바뀜\n",
    "print(df['착유시간대'].dtype)  # int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0683a37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"P/F ratio\"] = df[\"유단백\"]/ df[\"유지방\"]\n",
    "df[\"착유효율\"] = df[\"착유량\"] / df[\"착유시간\"]\n",
    "df[\"개체별 전도도율\"] = df.groupby(\"개체번호\")[\"전도도\"].transform(\"mean\")\n",
    "df['공기흐름_비율']=df['공기흐름']/df['착유시간'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9805e99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "착유량 하한: -6.00, 상한: 29.00\n",
      "착유회차 하한: -5.00, 상한: 9.00\n",
      "전도도 하한: 5.20, 상한: 8.70\n",
      "온도 하한: 36.50, 상한: 42.10\n",
      "유지방 하한: 0.80, 상한: 7.10\n",
      "유단백 하한: 2.10, 상한: 4.20\n",
      "공기흐름 하한: -2.20, 상한: 8.30\n",
      "착유시간 하한: -4.00, 상한: 17.00\n",
      "이상치 제거 전 행 수: 21658\n",
      "이상치 제거 후 행 수: 21050\n",
      "제거된 행 수: 608\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1) 이상치 제거할 한국어 컬럼 리스트\n",
    "outlier_cols = [\n",
    "    '착유량',\n",
    "    '착유회차',\n",
    "    '전도도',\n",
    "    '온도',\n",
    "    '유지방',\n",
    "    '유단백',\n",
    "    '공기흐름',\n",
    "    '착유시간'\n",
    "]\n",
    "\n",
    "# 2) 각 칼럼별 IQR 기반 하한·상한 계산 (3.0 × IQR)\n",
    "bounds = {}\n",
    "for col in outlier_cols:\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower = Q1 - 3 * IQR\n",
    "    upper = Q3 + 3 * IQR\n",
    "    bounds[col] = (lower, upper)\n",
    "    print(f\"{col} 하한: {lower:.2f}, 상한: {upper:.2f}\")\n",
    "\n",
    "# 3) 모든 칼럼이 허용 범위에 있는 행만 남기기\n",
    "mask = pd.Series(True, index=df.index)\n",
    "for col, (lower, upper) in bounds.items():\n",
    "    mask &= df[col].between(lower, upper)\n",
    "\n",
    "before = len(df)\n",
    "df_clean = df.loc[mask].copy()\n",
    "after = len(df_clean)\n",
    "\n",
    "print(f\"이상치 제거 전 행 수: {before}\")\n",
    "print(f\"이상치 제거 후 행 수: {after}\")\n",
    "print(f\"제거된 행 수: {before - after}\")\n",
    "# → 결과는 df_clean에 저장됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8559db1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit/transform 앞에 한 줄 추가\n",
    "df_clean.columns = [c.strip().replace(\" \", \"_\") for c in df_clean.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26b8d7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000442 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 822\n",
      "[LightGBM] [Info] Number of data points in the train set: 16840, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.778979\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000256 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 822\n",
      "[LightGBM] [Info] Number of data points in the train set: 16840, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.778979\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000153 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 822\n",
      "[LightGBM] [Info] Number of data points in the train set: 16840, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.778979\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001478 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 823\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001672 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 822\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001439 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 8\n",
      "[LightGBM] [Info] Total Bins 819\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001241 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000884 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 819\n",
      "[LightGBM] [Info] Total Bins 815\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 8\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 8\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 8\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.764326\n",
      "[LightGBM] [Info] Start training from score 11.769151\n",
      "[LightGBM] [Info] Start training from score 11.798248\n",
      "[LightGBM] [Info] Start training from score 11.787485\n",
      "[LightGBM] [Info] Start training from score 11.775683\n",
      "RF RMSE: 1.467, r2: 0.836, mae: 1.027, mape: 1166015105423.810\n",
      "XGB RMSE: 1.443, r2: 0.841, mae: 1.042, mape: 123078664192.000\n",
      "LGBM RMSE: 1.490, r2: 0.830, mae: 1.100, mape: 416786496830.037\n",
      "Voting RMSE: 1.407, r2: 0.849, mae: 1.015, mape: 208716649258.717\n",
      "Stacking RMSE: 1.399, r2: 0.851, mae: 1.004, mape: 90626548836.833\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor, VotingRegressor, StackingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "# 1) 데이터 준비\n",
    "y = df_clean['착유량']\n",
    "\n",
    "# drop target & 불필요 컬럼\n",
    "X = df_clean[[\"개체번호\",\"공기흐름_비율\",\"P/F_ratio\",\"개체별_착유일수\",\"측정일\",\"농장아이디\",\"착유시간\",'착유시간대']]\n",
    "# 2) 범주형 인코딩: 농장아이디, 개체번호\n",
    "cat_feats = ['농장아이디','개체번호']\n",
    "te = TargetEncoder(cols=cat_feats)\n",
    "X = te.fit_transform(X, y)\n",
    "\n",
    "# 3) Train/Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 4) 개별 모델 정의\n",
    "rf  = RandomForestRegressor(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "xgb = XGBRegressor(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "lgb = LGBMRegressor(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "\n",
    "# 5) 개별 모델 학습\n",
    "rf.fit(X_train, y_train)\n",
    "xgb.fit(X_train, y_train)\n",
    "lgb.fit(X_train, y_train)\n",
    "\n",
    "# 6) Voting 앙상블\n",
    "voting = VotingRegressor([('rf', rf), ('xgb', xgb), ('lgb', lgb)])\n",
    "voting.fit(X_train, y_train)\n",
    "\n",
    "# 7) Stacking 앙상블 (메타모델: Ridge)\n",
    "stack = StackingRegressor(\n",
    "    estimators=[('rf', rf), ('xgb', xgb), ('lgb', lgb)],\n",
    "    final_estimator=Ridge(),\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "stack.fit(X_train, y_train)\n",
    "\n",
    "# (8) 평가 예시\n",
    "for name, m in [('RF', rf), ('XGB', xgb), ('LGBM', lgb),\n",
    "                ('Voting', voting), ('Stacking', stack)]:\n",
    "    rmse = root_mean_squared_error(y_test, m.predict(X_test))\n",
    "    r2 = r2_score(y_test, m.predict(X_test))\n",
    "    mae = mean_absolute_error(y_test, m.predict(X_test))\n",
    "    mape = mean_absolute_percentage_error(y_test, m.predict(X_test))\n",
    "    print(f\"{name} RMSE: {rmse:.3f}, r2: {r2:.3f}, mae: {mae:.3f}, mape: {mape:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62b158a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000268 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 822\n",
      "[LightGBM] [Info] Number of data points in the train set: 16840, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.778979\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000318 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 822\n",
      "[LightGBM] [Info] Number of data points in the train set: 16840, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.778979\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000306 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 822\n",
      "[LightGBM] [Info] Number of data points in the train set: 16840, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.778979\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004569 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 819\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004973 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 823\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 8\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005036 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 815\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005911 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 819\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 8\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005619 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 822\n",
      "[LightGBM] [Info] Start training from score 11.764326\n",
      "[LightGBM] [Info] Start training from score 11.787485\n",
      "[LightGBM] [Info] Start training from score 11.775683\n",
      "[LightGBM] [Info] Start training from score 11.798248\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.769151\n",
      "RF RMSE: 1.467, r2: 0.836, mae: 1.027, mape: 1166015105423.810\n",
      "XGB RMSE: 1.443, r2: 0.841, mae: 1.042, mape: 123078664192.000\n",
      "LGBM RMSE: 1.490, r2: 0.830, mae: 1.100, mape: 416786496830.037\n",
      "Voting RMSE: 1.407, r2: 0.849, mae: 1.015, mape: 208716649258.717\n",
      "Stacking RMSE: 1.399, r2: 0.851, mae: 1.004, mape: 90626548836.833\n",
      "\n",
      "--- 교차검증 (5‑fold R²) & 과적합 정도 ---\n",
      "RF CV R2: 0.824 ± 0.002, Overfit: 0.012\n",
      "XGB CV R2: 0.832 ± 0.003, Overfit: 0.009\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003735 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 822\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.769151\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000286 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000746 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 823\n",
      "[LightGBM] [Info] Total Bins 819\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 8\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.764326\n",
      "[LightGBM] [Info] Start training from score 11.787485\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001755 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 819\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.798248\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000656 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 815\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.775683\n",
      "LGBM CV R2: 0.825 ± 0.005, Overfit: 0.005\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000251 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 822\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.769151\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000617 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 819\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.787485\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000386 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 815\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.775683\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000507 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 819\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.798248\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000735 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 823\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.764326\n",
      "Voting CV R2: 0.841 ± 0.003, Overfit: 0.008\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000911 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 819\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.787485\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000618 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 822\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.769151\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000764 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 819\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.798248\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000825 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 815\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.775683\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000439 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 823\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.764326\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002453 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 811\n",
      "[LightGBM] [Info] Number of data points in the train set: 10777, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.794841\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012979 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 821\n",
      "[LightGBM] [Info] Number of data points in the train set: 10777, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.771922\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022991 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 813\n",
      "[LightGBM] [Info] Number of data points in the train set: 10777, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.798089\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001772 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 817\n",
      "[LightGBM] [Info] Number of data points in the train set: 10777, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.808295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000928 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 823\n",
      "[LightGBM] [Info] Number of data points in the train set: 10777, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.765890\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000667 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 818\n",
      "[LightGBM] [Info] Number of data points in the train set: 10777, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.769231\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000458 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 821\n",
      "[LightGBM] [Info] Number of data points in the train set: 10777, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.767468\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000426 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 816\n",
      "[LightGBM] [Info] Number of data points in the train set: 10777, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.785469\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000971 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 815\n",
      "[LightGBM] [Info] Number of data points in the train set: 10777, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.811636\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000444 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 821\n",
      "[LightGBM] [Info] Number of data points in the train set: 10777, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.775262\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000423 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 820\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.750046\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000604 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 822\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.764799\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001749 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 823\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.751438\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000520 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 827\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.793839\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000616 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 825\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.752088\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005314 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 818\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.769994\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000642 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 817\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.784747\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000534 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 824\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.756448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002108 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 822\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.761830\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017418 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 821\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.782520\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000931 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 818\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.807571\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000282 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 812\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.792819\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001479 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 820\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.778623\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000503 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 820\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.784654\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.147614 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 820\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.794953\n",
      "Stacking CV R2: 0.842 ± 0.003, Overfit: 0.009\n",
      "\n",
      "--- 피처 중요도 순위 (RF / XGB / LGBM) ---\n",
      "\n",
      "RF Feature Importances:\n",
      "      Feature  Importance\n",
      "0       개체번호    0.581117\n",
      "1       착유시간    0.111514\n",
      "2    공기흐름_비율    0.109293\n",
      "3  P/F_ratio    0.099480\n",
      "4        측정일    0.042217\n",
      "5      착유시간대    0.020026\n",
      "6      농장아이디    0.019475\n",
      "7   개체별_착유일수    0.016879\n",
      "\n",
      "XGB Feature Importances:\n",
      "      Feature  Importance\n",
      "0       개체번호    0.431064\n",
      "1       착유시간    0.248631\n",
      "2    공기흐름_비율    0.076900\n",
      "3      농장아이디    0.070927\n",
      "4  P/F_ratio    0.058404\n",
      "5   개체별_착유일수    0.050782\n",
      "6      착유시간대    0.041501\n",
      "7        측정일    0.021792\n",
      "\n",
      "LGBM Feature Importances:\n",
      "      Feature  Importance\n",
      "0       개체번호        1477\n",
      "1    공기흐름_비율        1289\n",
      "2  P/F_ratio        1063\n",
      "3       착유시간         778\n",
      "4        측정일         513\n",
      "5   개체별_착유일수         347\n",
      "6      농장아이디         287\n",
      "7      착유시간대         246\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor, VotingRegressor, StackingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "# 1) 데이터 준비\n",
    "y = df_clean['착유량']\n",
    "\n",
    "# drop target & 불필요 컬럼\n",
    "X = df_clean[[\"개체번호\",\"공기흐름_비율\",\"P/F_ratio\",\"개체별_착유일수\",\"측정일\",\"농장아이디\",'착유시간', '착유시간대']]\n",
    "\n",
    "# 2) 범주형 인코딩: 농장아이디, 개체번호\n",
    "cat_feats = ['농장아이디','개체번호']\n",
    "te = TargetEncoder(cols=cat_feats)\n",
    "X = te.fit_transform(X, y)\n",
    "\n",
    "# 3) Train/Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 4) 개별 모델 정의\n",
    "rf  = RandomForestRegressor(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "xgb = XGBRegressor(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "lgb = LGBMRegressor(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "\n",
    "# 5) 개별 모델 학습\n",
    "rf.fit(X_train, y_train)\n",
    "xgb.fit(X_train, y_train)\n",
    "lgb.fit(X_train, y_train)\n",
    "\n",
    "# 6) Voting 앙상블\n",
    "voting = VotingRegressor([('rf', rf), ('xgb', xgb), ('lgb', lgb)])\n",
    "voting.fit(X_train, y_train)\n",
    "\n",
    "# 7) Stacking 앙상블 (메타모델: Ridge)\n",
    "stack = StackingRegressor(\n",
    "    estimators=[('rf', rf), ('xgb', xgb), ('lgb', lgb)],\n",
    "    final_estimator=Ridge(),\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "stack.fit(X_train, y_train)\n",
    "\n",
    "# 8) 평가 예시\n",
    "for name, m in [('RF', rf), ('XGB', xgb), ('LGBM', lgb),\n",
    "                ('Voting', voting), ('Stacking', stack)]:\n",
    "    rmse = root_mean_squared_error(y_test, m.predict(X_test))\n",
    "    r2 = r2_score(y_test, m.predict(X_test))\n",
    "    mae = mean_absolute_error(y_test, m.predict(X_test))\n",
    "    mape = mean_absolute_percentage_error(y_test, m.predict(X_test))\n",
    "    print(f\"{name} RMSE: {rmse:.3f}, r2: {r2:.3f}, mae: {mae:.3f}, mape: {mape:.3f}\")\n",
    "\n",
    "# 9) 교차검증으로 과적합 체크\n",
    "print(\"\\n--- 교차검증 (5‑fold R²) & 과적합 정도 ---\")\n",
    "for name, m in [('RF', rf), ('XGB', xgb), ('LGBM', lgb),\n",
    "                ('Voting', voting), ('Stacking', stack)]:\n",
    "    cv_scores = cross_val_score(m, X_train, y_train, cv=5, scoring='r2', n_jobs=-1)\n",
    "    test_r2 = r2_score(y_test, m.predict(X_test))\n",
    "    print(f\"{name} CV R2: {cv_scores.mean():.3f} ± {cv_scores.std():.3f}, Overfit: {abs(cv_scores.mean() - test_r2):.3f}\")\n",
    "\n",
    "# 10) 피처 중요도 분석\n",
    "print(\"\\n--- 피처 중요도 순위 (RF / XGB / LGBM) ---\")\n",
    "feature_names = X_train.columns\n",
    "for name, m in [('RF', rf), ('XGB', xgb), ('LGBM', lgb)]:\n",
    "    importance = m.feature_importances_\n",
    "    fi_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': importance\n",
    "    }).sort_values('Importance', ascending=False).reset_index(drop=True)\n",
    "    print(f\"\\n{name} Feature Importances:\\n\", fi_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f019fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     feature    rf_imp   xgb_imp  lgb_imp\n",
      "0       개체번호  0.581117  0.431064     1477\n",
      "1       착유시간  0.111514  0.248631      778\n",
      "2    공기흐름_비율  0.109293  0.076900     1289\n",
      "3  P/F_ratio  0.099480  0.058404     1063\n",
      "4        측정일  0.042217  0.021792      513\n",
      "5      착유시간대  0.020026  0.041501      246\n",
      "6      농장아이디  0.019475  0.070927      287\n",
      "7   개체별_착유일수  0.016879  0.050782      347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6n/tjcbrygj54s39y61m4r7ymrr0000gq/T/ipykernel_46343/2188460230.py:24: UserWarning: Glyph 44060 (\\N{HANGUL SYLLABLE GAE}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/6n/tjcbrygj54s39y61m4r7ymrr0000gq/T/ipykernel_46343/2188460230.py:24: UserWarning: Glyph 52404 (\\N{HANGUL SYLLABLE CE}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/6n/tjcbrygj54s39y61m4r7ymrr0000gq/T/ipykernel_46343/2188460230.py:24: UserWarning: Glyph 48324 (\\N{HANGUL SYLLABLE BYEOL}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/6n/tjcbrygj54s39y61m4r7ymrr0000gq/T/ipykernel_46343/2188460230.py:24: UserWarning: Glyph 52265 (\\N{HANGUL SYLLABLE CAG}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/6n/tjcbrygj54s39y61m4r7ymrr0000gq/T/ipykernel_46343/2188460230.py:24: UserWarning: Glyph 50976 (\\N{HANGUL SYLLABLE YU}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/6n/tjcbrygj54s39y61m4r7ymrr0000gq/T/ipykernel_46343/2188460230.py:24: UserWarning: Glyph 51068 (\\N{HANGUL SYLLABLE IL}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/6n/tjcbrygj54s39y61m4r7ymrr0000gq/T/ipykernel_46343/2188460230.py:24: UserWarning: Glyph 49688 (\\N{HANGUL SYLLABLE SU}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/6n/tjcbrygj54s39y61m4r7ymrr0000gq/T/ipykernel_46343/2188460230.py:24: UserWarning: Glyph 45453 (\\N{HANGUL SYLLABLE NONG}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/6n/tjcbrygj54s39y61m4r7ymrr0000gq/T/ipykernel_46343/2188460230.py:24: UserWarning: Glyph 51109 (\\N{HANGUL SYLLABLE JANG}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/6n/tjcbrygj54s39y61m4r7ymrr0000gq/T/ipykernel_46343/2188460230.py:24: UserWarning: Glyph 50500 (\\N{HANGUL SYLLABLE A}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/6n/tjcbrygj54s39y61m4r7ymrr0000gq/T/ipykernel_46343/2188460230.py:24: UserWarning: Glyph 51060 (\\N{HANGUL SYLLABLE I}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/6n/tjcbrygj54s39y61m4r7ymrr0000gq/T/ipykernel_46343/2188460230.py:24: UserWarning: Glyph 46356 (\\N{HANGUL SYLLABLE DI}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/6n/tjcbrygj54s39y61m4r7ymrr0000gq/T/ipykernel_46343/2188460230.py:24: UserWarning: Glyph 49884 (\\N{HANGUL SYLLABLE SI}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/6n/tjcbrygj54s39y61m4r7ymrr0000gq/T/ipykernel_46343/2188460230.py:24: UserWarning: Glyph 44036 (\\N{HANGUL SYLLABLE GAN}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/6n/tjcbrygj54s39y61m4r7ymrr0000gq/T/ipykernel_46343/2188460230.py:24: UserWarning: Glyph 45824 (\\N{HANGUL SYLLABLE DAE}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/6n/tjcbrygj54s39y61m4r7ymrr0000gq/T/ipykernel_46343/2188460230.py:24: UserWarning: Glyph 52769 (\\N{HANGUL SYLLABLE CEUG}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/6n/tjcbrygj54s39y61m4r7ymrr0000gq/T/ipykernel_46343/2188460230.py:24: UserWarning: Glyph 51221 (\\N{HANGUL SYLLABLE JEONG}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/6n/tjcbrygj54s39y61m4r7ymrr0000gq/T/ipykernel_46343/2188460230.py:24: UserWarning: Glyph 44277 (\\N{HANGUL SYLLABLE GONG}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/6n/tjcbrygj54s39y61m4r7ymrr0000gq/T/ipykernel_46343/2188460230.py:24: UserWarning: Glyph 44592 (\\N{HANGUL SYLLABLE GI}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/6n/tjcbrygj54s39y61m4r7ymrr0000gq/T/ipykernel_46343/2188460230.py:24: UserWarning: Glyph 55120 (\\N{HANGUL SYLLABLE HEU}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/6n/tjcbrygj54s39y61m4r7ymrr0000gq/T/ipykernel_46343/2188460230.py:24: UserWarning: Glyph 47492 (\\N{HANGUL SYLLABLE REUM}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/6n/tjcbrygj54s39y61m4r7ymrr0000gq/T/ipykernel_46343/2188460230.py:24: UserWarning: Glyph 48708 (\\N{HANGUL SYLLABLE BI}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/6n/tjcbrygj54s39y61m4r7ymrr0000gq/T/ipykernel_46343/2188460230.py:24: UserWarning: Glyph 50984 (\\N{HANGUL SYLLABLE YUL}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/6n/tjcbrygj54s39y61m4r7ymrr0000gq/T/ipykernel_46343/2188460230.py:24: UserWarning: Glyph 48264 (\\N{HANGUL SYLLABLE BEON}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/6n/tjcbrygj54s39y61m4r7ymrr0000gq/T/ipykernel_46343/2188460230.py:24: UserWarning: Glyph 54840 (\\N{HANGUL SYLLABLE HO}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 44060 (\\N{HANGUL SYLLABLE GAE}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 52404 (\\N{HANGUL SYLLABLE CE}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 48324 (\\N{HANGUL SYLLABLE BYEOL}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 52265 (\\N{HANGUL SYLLABLE CAG}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 50976 (\\N{HANGUL SYLLABLE YU}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 51068 (\\N{HANGUL SYLLABLE IL}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 49688 (\\N{HANGUL SYLLABLE SU}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 45453 (\\N{HANGUL SYLLABLE NONG}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 51109 (\\N{HANGUL SYLLABLE JANG}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 50500 (\\N{HANGUL SYLLABLE A}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 51060 (\\N{HANGUL SYLLABLE I}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 46356 (\\N{HANGUL SYLLABLE DI}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 49884 (\\N{HANGUL SYLLABLE SI}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 44036 (\\N{HANGUL SYLLABLE GAN}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 45824 (\\N{HANGUL SYLLABLE DAE}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 52769 (\\N{HANGUL SYLLABLE CEUG}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 51221 (\\N{HANGUL SYLLABLE JEONG}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 44277 (\\N{HANGUL SYLLABLE GONG}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 44592 (\\N{HANGUL SYLLABLE GI}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 55120 (\\N{HANGUL SYLLABLE HEU}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 47492 (\\N{HANGUL SYLLABLE REUM}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 48708 (\\N{HANGUL SYLLABLE BI}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 50984 (\\N{HANGUL SYLLABLE YUL}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 48264 (\\N{HANGUL SYLLABLE BEON}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 54840 (\\N{HANGUL SYLLABLE HO}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     feature        VIF\n",
      "5      농장아이디  70.155446\n",
      "0       개체번호  33.527488\n",
      "6       착유시간  33.337912\n",
      "2  P/F_ratio  19.925134\n",
      "3   개체별_착유일수  13.205340\n",
      "1    공기흐름_비율  10.361573\n",
      "7      착유시간대   6.111497\n",
      "4        측정일   5.843568\n",
      "               개체번호   공기흐름_비율  P/F_ratio  개체별_착유일수       측정일     농장아이디  \\\n",
      "개체번호       1.000000 -0.090886   0.185817 -0.195196  0.084266  0.352331   \n",
      "공기흐름_비율   -0.090886  1.000000   0.005972 -0.067393 -0.002562  0.107154   \n",
      "P/F_ratio  0.185817  0.005972   1.000000 -0.048438  0.054121  0.112346   \n",
      "개체별_착유일수  -0.195196 -0.067393  -0.048438  1.000000 -0.342203 -0.584931   \n",
      "측정일        0.084266 -0.002562   0.054121 -0.342203  1.000000  0.220689   \n",
      "농장아이디      0.352331  0.107154   0.112346 -0.584931  0.220689  1.000000   \n",
      "착유시간       0.347120 -0.749904   0.124277  0.050839  0.037579  0.014886   \n",
      "착유시간대      0.000045 -0.014142   0.031478 -0.036026  0.019052 -0.056883   \n",
      "\n",
      "               착유시간     착유시간대  \n",
      "개체번호       0.347120  0.000045  \n",
      "공기흐름_비율   -0.749904 -0.014142  \n",
      "P/F_ratio  0.124277  0.031478  \n",
      "개체별_착유일수   0.050839 -0.036026  \n",
      "측정일        0.037579  0.019052  \n",
      "농장아이디      0.014886 -0.056883  \n",
      "착유시간       1.000000  0.019671  \n",
      "착유시간대      0.019671  1.000000  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/seaborn/utils.py:61: UserWarning: Glyph 44060 (\\N{HANGUL SYLLABLE GAE}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.draw()\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/seaborn/utils.py:61: UserWarning: Glyph 52404 (\\N{HANGUL SYLLABLE CE}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.draw()\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/seaborn/utils.py:61: UserWarning: Glyph 48264 (\\N{HANGUL SYLLABLE BEON}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.draw()\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/seaborn/utils.py:61: UserWarning: Glyph 54840 (\\N{HANGUL SYLLABLE HO}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.draw()\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/seaborn/utils.py:61: UserWarning: Glyph 44277 (\\N{HANGUL SYLLABLE GONG}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.draw()\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/seaborn/utils.py:61: UserWarning: Glyph 44592 (\\N{HANGUL SYLLABLE GI}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.draw()\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/seaborn/utils.py:61: UserWarning: Glyph 55120 (\\N{HANGUL SYLLABLE HEU}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.draw()\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/seaborn/utils.py:61: UserWarning: Glyph 47492 (\\N{HANGUL SYLLABLE REUM}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.draw()\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/seaborn/utils.py:61: UserWarning: Glyph 48708 (\\N{HANGUL SYLLABLE BI}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.draw()\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/seaborn/utils.py:61: UserWarning: Glyph 50984 (\\N{HANGUL SYLLABLE YUL}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.draw()\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/seaborn/utils.py:61: UserWarning: Glyph 48324 (\\N{HANGUL SYLLABLE BYEOL}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.draw()\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/seaborn/utils.py:61: UserWarning: Glyph 52265 (\\N{HANGUL SYLLABLE CAG}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.draw()\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/seaborn/utils.py:61: UserWarning: Glyph 50976 (\\N{HANGUL SYLLABLE YU}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.draw()\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/seaborn/utils.py:61: UserWarning: Glyph 51068 (\\N{HANGUL SYLLABLE IL}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.draw()\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/seaborn/utils.py:61: UserWarning: Glyph 49688 (\\N{HANGUL SYLLABLE SU}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.draw()\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/seaborn/utils.py:61: UserWarning: Glyph 52769 (\\N{HANGUL SYLLABLE CEUG}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.draw()\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/seaborn/utils.py:61: UserWarning: Glyph 51221 (\\N{HANGUL SYLLABLE JEONG}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.draw()\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/seaborn/utils.py:61: UserWarning: Glyph 45453 (\\N{HANGUL SYLLABLE NONG}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.draw()\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/seaborn/utils.py:61: UserWarning: Glyph 51109 (\\N{HANGUL SYLLABLE JANG}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.draw()\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/seaborn/utils.py:61: UserWarning: Glyph 50500 (\\N{HANGUL SYLLABLE A}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.draw()\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/seaborn/utils.py:61: UserWarning: Glyph 51060 (\\N{HANGUL SYLLABLE I}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.draw()\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/seaborn/utils.py:61: UserWarning: Glyph 46356 (\\N{HANGUL SYLLABLE DI}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.draw()\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/seaborn/utils.py:61: UserWarning: Glyph 49884 (\\N{HANGUL SYLLABLE SI}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.draw()\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/seaborn/utils.py:61: UserWarning: Glyph 44036 (\\N{HANGUL SYLLABLE GAN}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.draw()\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/seaborn/utils.py:61: UserWarning: Glyph 45824 (\\N{HANGUL SYLLABLE DAE}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.draw()\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 44060 (\\N{HANGUL SYLLABLE GAE}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 52404 (\\N{HANGUL SYLLABLE CE}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 48264 (\\N{HANGUL SYLLABLE BEON}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 54840 (\\N{HANGUL SYLLABLE HO}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 44277 (\\N{HANGUL SYLLABLE GONG}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 44592 (\\N{HANGUL SYLLABLE GI}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 55120 (\\N{HANGUL SYLLABLE HEU}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 47492 (\\N{HANGUL SYLLABLE REUM}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 48708 (\\N{HANGUL SYLLABLE BI}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 50984 (\\N{HANGUL SYLLABLE YUL}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 48324 (\\N{HANGUL SYLLABLE BYEOL}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 52265 (\\N{HANGUL SYLLABLE CAG}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 50976 (\\N{HANGUL SYLLABLE YU}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 51068 (\\N{HANGUL SYLLABLE IL}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 49688 (\\N{HANGUL SYLLABLE SU}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 52769 (\\N{HANGUL SYLLABLE CEUG}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 51221 (\\N{HANGUL SYLLABLE JEONG}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 45453 (\\N{HANGUL SYLLABLE NONG}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 51109 (\\N{HANGUL SYLLABLE JANG}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 50500 (\\N{HANGUL SYLLABLE A}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 51060 (\\N{HANGUL SYLLABLE I}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 46356 (\\N{HANGUL SYLLABLE DI}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 49884 (\\N{HANGUL SYLLABLE SI}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 44036 (\\N{HANGUL SYLLABLE GAN}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 45824 (\\N{HANGUL SYLLABLE DAE}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# X_train 은 pandas.DataFrame, rf/xgb/lgb 는 이미 fit된 모델이라고 가정\n",
    "\n",
    "# 1) 중요도 추출\n",
    "imp_df = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'rf_imp':  rf.feature_importances_,\n",
    "    'xgb_imp': xgb.feature_importances_,\n",
    "    'lgb_imp': lgb.feature_importances_\n",
    "})\n",
    "\n",
    "# 2) 보기 좋게 정렬 (여기서는 랜덤포레스트 기준으로)\n",
    "imp_df = imp_df.sort_values('rf_imp', ascending=False).reset_index(drop=True)\n",
    "print(imp_df)\n",
    "\n",
    "# 3) 시각화 (상위 10개)\n",
    "topn = 10\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax.barh(imp_df['feature'].iloc[:topn][::-1], imp_df['rf_imp'].iloc[:topn][::-1])\n",
    "ax.set_xlabel(\"RF Feature Importance\")\n",
    "ax.set_title(f\"Top {topn} Features by RF\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# X 는 학습에 사용할 피처 DataFrame (상수항은 statsmodels 에서 자동 추가)\n",
    "# 필요시 수치형만 선택: X = X.select_dtypes(include='number')\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data['feature'] = X.columns\n",
    "vif_data['VIF'] = [\n",
    "    variance_inflation_factor(X.values, i)\n",
    "    for i in range(X.shape[1])\n",
    "]\n",
    "print(vif_data.sort_values('VIF', ascending=False))\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# X 는 피처 DataFrame\n",
    "corr = X.corr()\n",
    "# 상관계수 매트릭스 출력\n",
    "print(corr)\n",
    "\n",
    "# 히트맵으로 시각화 (선택)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"RdBu_r\", center=0)\n",
    "plt.title(\"Feature Correlation Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d5fc60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001416 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 822\n",
      "[LightGBM] [Info] Number of data points in the train set: 16840, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.778979\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000340 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 822\n",
      "[LightGBM] [Info] Number of data points in the train set: 16840, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.778979\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000163 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 822\n",
      "[LightGBM] [Info] Number of data points in the train set: 16840, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.778979\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000293 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 823\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.764326\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019715 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 815\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021102 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 819\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 819\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019559 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 822\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 8\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 8\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 8\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.798248\n",
      "[LightGBM] [Info] Start training from score 11.775683\n",
      "[LightGBM] [Info] Start training from score 11.769151\n",
      "[LightGBM] [Info] Start training from score 11.787485\n",
      "RF RMSE: 1.467, R²: 0.836, MAE: 1.027, MAPE: 9.50%\n",
      "XGB RMSE: 1.443, R²: 0.841, MAE: 1.042, MAPE: 9.55%\n",
      "LGBM RMSE: 1.490, R²: 0.830, MAE: 1.100, MAPE: 10.08%\n",
      "Voting RMSE: 1.407, R²: 0.849, MAE: 1.015, MAPE: 9.34%\n",
      "Stacking RMSE: 1.399, R²: 0.851, MAE: 1.004, MAPE: 9.19%\n",
      "\n",
      "--- 교차검증 (5‑fold R²) & 과적합 정도 ---\n",
      "RF CV R2: 0.824 ± 0.002, Overfit: 0.012\n",
      "XGB CV R2: 0.832 ± 0.003, Overfit: 0.009\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001794 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 822\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.769151\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000621 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 819\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.787485\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000268 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 819\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.798248\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000643 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 823\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.764326\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001268 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 815\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.775683\n",
      "LGBM CV R2: 0.825 ± 0.005, Overfit: 0.005\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002086 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 819\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.787485\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000564 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 822\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.769151\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000482 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 815\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.775683\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000800 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 823\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.764326\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000524 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 819\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.798248\n",
      "Voting CV R2: 0.841 ± 0.003, Overfit: 0.008\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003835 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 819\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.787485\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000737 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 822\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.769151\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001664 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 823\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.764326\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001597 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 815\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.775683\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000566 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 819\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.798248\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000420 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 811\n",
      "[LightGBM] [Info] Number of data points in the train set: 10777, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.794841\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005467 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 813\n",
      "[LightGBM] [Info] Number of data points in the train set: 10777, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.798089\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002025 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 823\n",
      "[LightGBM] [Info] Number of data points in the train set: 10777, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.765890\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000890 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 821\n",
      "[LightGBM] [Info] Number of data points in the train set: 10777, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.771922\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000393 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 817\n",
      "[LightGBM] [Info] Number of data points in the train set: 10777, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.808295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000640 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 815\n",
      "[LightGBM] [Info] Number of data points in the train set: 10777, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.811636\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000730 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 818\n",
      "[LightGBM] [Info] Number of data points in the train set: 10777, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.769231\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000959 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 821\n",
      "[LightGBM] [Info] Number of data points in the train set: 10777, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.775262\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000749 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 816\n",
      "[LightGBM] [Info] Number of data points in the train set: 10777, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.785469\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000645 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 821\n",
      "[LightGBM] [Info] Number of data points in the train set: 10777, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.767468\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000371 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 827\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.793839\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004770 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 823\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.751438\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000504 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 825\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.752088\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000697 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 820\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.750046\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000599 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 822\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.764799\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000624 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 821\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.782520\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000346 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 822\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.761830\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006908 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 824\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.756448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000520 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 818\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.769994\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012292 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 817\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.784747\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007081 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 820\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.794953\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000389 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 820\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.784654\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000500 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 820\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.778623\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 818\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.807571\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000688 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 812\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 11.792819\n",
      "Stacking CV R2: 0.842 ± 0.003, Overfit: 0.009\n",
      "\n",
      "--- 피처 중요도 순위 (RF / XGB / LGBM) ---\n",
      "\n",
      "RF Feature Importances:\n",
      "      Feature  Importance\n",
      "0       개체번호    0.581117\n",
      "1       착유시간    0.111514\n",
      "2    공기흐름_비율    0.109293\n",
      "3  P/F_ratio    0.099480\n",
      "4        측정일    0.042217\n",
      "5      착유시간대    0.020026\n",
      "6      농장아이디    0.019475\n",
      "7   개체별_착유일수    0.016879\n",
      "\n",
      "XGB Feature Importances:\n",
      "      Feature  Importance\n",
      "0       개체번호    0.431064\n",
      "1       착유시간    0.248631\n",
      "2    공기흐름_비율    0.076900\n",
      "3      농장아이디    0.070927\n",
      "4  P/F_ratio    0.058404\n",
      "5   개체별_착유일수    0.050782\n",
      "6      착유시간대    0.041501\n",
      "7        측정일    0.021792\n",
      "\n",
      "LGBM Feature Importances:\n",
      "      Feature  Importance\n",
      "0       개체번호        1477\n",
      "1    공기흐름_비율        1289\n",
      "2  P/F_ratio        1063\n",
      "3       착유시간         778\n",
      "4        측정일         513\n",
      "5   개체별_착유일수         347\n",
      "6      농장아이디         287\n",
      "7      착유시간대         246\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor, VotingRegressor, StackingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "# 1) 데이터 준비\n",
    "y = df_clean['착유량']\n",
    "\n",
    "# drop target & 불필요 컬럼\n",
    "X = df_clean[[\"개체번호\",\"공기흐름_비율\",\"P/F_ratio\",\"개체별_착유일수\",\"측정일\",\"농장아이디\",'착유시간', '착유시간대']]\n",
    "\n",
    "# 2) 범주형 인코딩: 농장아이디, 개체번호\n",
    "cat_feats = ['농장아이디','개체번호']\n",
    "te = TargetEncoder(cols=cat_feats)\n",
    "X = te.fit_transform(X, y)\n",
    "\n",
    "# 3) Train/Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 4) 개별 모델 정의\n",
    "rf  = RandomForestRegressor(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "xgb = XGBRegressor(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "lgb = LGBMRegressor(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "\n",
    "# 5) 개별 모델 학습\n",
    "rf.fit(X_train, y_train)\n",
    "xgb.fit(X_train, y_train)\n",
    "lgb.fit(X_train, y_train)\n",
    "\n",
    "# 6) Voting 앙상블\n",
    "voting = VotingRegressor([('rf', rf), ('xgb', xgb), ('lgb', lgb)])\n",
    "voting.fit(X_train, y_train)\n",
    "\n",
    "# 7) Stacking 앙상블 (메타모델: Ridge)\n",
    "stack = StackingRegressor(\n",
    "    estimators=[('rf', rf), ('xgb', xgb), ('lgb', lgb)],\n",
    "    final_estimator=Ridge(),\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "stack.fit(X_train, y_train)\n",
    "\n",
    "# --- 8) 평가 예시 (mape 계산 로직 수정) ---\n",
    "for name, m in [\n",
    "    ('RF', rf), ('XGB', xgb), ('LGBM', lgb),\n",
    "    ('Voting', voting), ('Stacking', stack)\n",
    "]:\n",
    "    y_pred = m.predict(X_test)\n",
    "\n",
    "    rmse = root_mean_squared_error(y_test, y_pred)\n",
    "    r2   = r2_score(y_test, y_pred)\n",
    "    mae  = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    # 1) y_test가 0이 아닌 인덱스만 골라서 MAPE 계산\n",
    "    nonzero_mask = y_test != 0\n",
    "    mape = mean_absolute_percentage_error(\n",
    "        y_test[nonzero_mask],\n",
    "        y_pred[nonzero_mask]\n",
    "    ) * 100  # 비율 → 퍼센트\n",
    "\n",
    "    print(\n",
    "        f\"{name} \"\n",
    "        f\"RMSE: {rmse:.3f}, \"\n",
    "        f\"R²: {r2:.3f}, \"\n",
    "        f\"MAE: {mae:.3f}, \"\n",
    "        f\"MAPE: {mape:.2f}%\"\n",
    "    )\n",
    "\n",
    "# 9) 교차검증으로 과적합 체크\n",
    "print(\"\\n--- 교차검증 (5‑fold R²) & 과적합 정도 ---\")\n",
    "for name, m in [('RF', rf), ('XGB', xgb), ('LGBM', lgb),\n",
    "                ('Voting', voting), ('Stacking', stack)]:\n",
    "    cv_scores = cross_val_score(m, X_train, y_train, cv=5, scoring='r2', n_jobs=-1)\n",
    "    test_r2 = r2_score(y_test, m.predict(X_test))\n",
    "    print(f\"{name} CV R2: {cv_scores.mean():.3f} ± {cv_scores.std():.3f}, Overfit: {abs(cv_scores.mean() - test_r2):.3f}\")\n",
    "\n",
    "# 10) 피처 중요도 분석\n",
    "print(\"\\n--- 피처 중요도 순위 (RF / XGB / LGBM) ---\")\n",
    "feature_names = X_train.columns\n",
    "for name, m in [('RF', rf), ('XGB', xgb), ('LGBM', lgb)]:\n",
    "    importance = m.feature_importances_\n",
    "    fi_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': importance\n",
    "    }).sort_values('Importance', ascending=False).reset_index(drop=True)\n",
    "    print(f\"\\n{name} Feature Importances:\\n\", fi_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2ab2fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000698 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 872\n",
      "[LightGBM] [Info] Number of data points in the train set: 16840, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 11.778979\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000347 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 872\n",
      "[LightGBM] [Info] Number of data points in the train set: 16840, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 11.778979\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001284 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 872\n",
      "[LightGBM] [Info] Number of data points in the train set: 16840, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 11.778979\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000333 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 871\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008827 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 863\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009734 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 868\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009588 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 867\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003605 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 9\n",
      "[LightGBM] [Info] Total Bins 871\n",
      "[LightGBM] [Info] Start training from score 11.787485\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 9\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 11.764326\n",
      "[LightGBM] [Info] Start training from score 11.769151\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 9\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 11.798248\n",
      "[LightGBM] [Info] Start training from score 11.775683\n",
      "RF RMSE: 1.462, R²: 0.837, MAE: 1.027, MAPE: 9.52%\n",
      "XGB RMSE: 1.428, R²: 0.844, MAE: 1.036, MAPE: 9.48%\n",
      "LGBM RMSE: 1.465, R²: 0.836, MAE: 1.087, MAPE: 9.87%\n",
      "Voting RMSE: 1.390, R²: 0.853, MAE: 1.006, MAPE: 9.22%\n",
      "Stacking RMSE: 1.382, R²: 0.854, MAE: 0.997, MAPE: 9.09%\n",
      "\n",
      "--- 교차검증 (5‑fold R²) & 과적합 정도 ---\n",
      "RF CV R2: 0.824 ± 0.001, Overfit: 0.013\n",
      "XGB CV R2: 0.834 ± 0.003, Overfit: 0.010\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000499 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 868\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 11.787485\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001052 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 871\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 11.769151\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000664 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 871\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 11.764326\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000619 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 867\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 11.798248\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000564 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 863\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 11.775683\n",
      "LGBM CV R2: 0.828 ± 0.005, Overfit: 0.008\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000390 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 868\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 11.787485\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007995 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 863\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 11.775683\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000679 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 871\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 11.764326\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000603 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 867\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 11.798248\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000572 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 871\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 11.769151\n",
      "Voting CV R2: 0.843 ± 0.003, Overfit: 0.010\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022960 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 868\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 9\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044802 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 871\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 11.787485\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019519 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 867\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046027 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 863\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 9\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 11.769151\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022070 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 871\n",
      "[LightGBM] [Info] Start training from score 11.798248\n",
      "[LightGBM] [Info] Start training from score 11.775683\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 11.764326\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000893 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 859\n",
      "[LightGBM] [Info] Number of data points in the train set: 10777, number of used features: 9\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001119 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 869\n",
      "[LightGBM] [Info] Start training from score 11.794841[LightGBM] [Info] Number of data points in the train set: 10777, number of used features: 9\n",
      "\n",
      "[LightGBM] [Info] Start training from score 11.771922\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000721 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 861\n",
      "[LightGBM] [Info] Number of data points in the train set: 10777, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 11.798089\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000662 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 869\n",
      "[LightGBM] [Info] Number of data points in the train set: 10777, number of used features: 9\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000811 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 865\n",
      "[LightGBM] [Info] Start training from score 11.765890\n",
      "[LightGBM] [Info] Number of data points in the train set: 10777, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 11.808295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.073526 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 862\n",
      "[LightGBM] [Info] Number of data points in the train set: 10777, number of used features: 9\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001601 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 865\n",
      "[LightGBM] [Info] Number of data points in the train set: 10777, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 11.785469\n",
      "[LightGBM] [Info] Start training from score 11.811636\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000436 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 869\n",
      "[LightGBM] [Info] Number of data points in the train set: 10777, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 11.767468\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002549 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 869\n",
      "[LightGBM] [Info] Number of data points in the train set: 10777, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 11.775262\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000523 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 865\n",
      "[LightGBM] [Info] Number of data points in the train set: 10777, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 11.769231\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000423 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 868\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 11.750046\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001035 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 869\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 11.764799\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000490 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 875\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 11.793839\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000511 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 873\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 11.752088\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000355 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 870\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 11.751438\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000473 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 864\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 11.769994\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000274 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 865\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 11.784747\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001670 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 868\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 11.782520\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000768 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 871\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 11.761830\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000630 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 871\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 11.756448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000294 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 860\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 11.792819\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000557 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 866\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 11.807571\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000825 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 866\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 11.794953\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000371 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 868\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 11.784654\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000597 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 867\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 11.778623\n",
      "Stacking CV R2: 0.844 ± 0.003, Overfit: 0.010\n",
      "\n",
      "--- 피처 중요도 순위 (RF / XGB / LGBM) ---\n",
      "\n",
      "RF Feature Importances:\n",
      "      Feature  Importance\n",
      "0       개체번호    0.575976\n",
      "1       착유시간    0.108472\n",
      "2    공기흐름_비율    0.099501\n",
      "3  P/F_ratio    0.092421\n",
      "4         온도    0.039986\n",
      "5        측정일    0.035674\n",
      "6      착유시간대    0.016879\n",
      "7      농장아이디    0.016133\n",
      "8   개체별_착유일수    0.014958\n",
      "\n",
      "XGB Feature Importances:\n",
      "      Feature  Importance\n",
      "0       개체번호    0.408690\n",
      "1       착유시간    0.254733\n",
      "2      농장아이디    0.070507\n",
      "3    공기흐름_비율    0.069528\n",
      "4  P/F_ratio    0.055866\n",
      "5   개체별_착유일수    0.049249\n",
      "6      착유시간대    0.036261\n",
      "7         온도    0.035467\n",
      "8        측정일    0.019698\n",
      "\n",
      "LGBM Feature Importances:\n",
      "      Feature  Importance\n",
      "0       개체번호        1372\n",
      "1    공기흐름_비율        1208\n",
      "2  P/F_ratio         985\n",
      "3       착유시간         741\n",
      "4        측정일         463\n",
      "5         온도         428\n",
      "6   개체별_착유일수         316\n",
      "7      농장아이디         285\n",
      "8      착유시간대         202\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor, VotingRegressor, StackingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "# 1) 데이터 준비\n",
    "y = df_clean['착유량']\n",
    "\n",
    "# drop target & 불필요 컬럼\n",
    "X = df_clean[[\"개체번호\",\"공기흐름_비율\",\"P/F_ratio\",\"개체별_착유일수\",\"측정일\",\"농장아이디\",'착유시간', '착유시간대', '온도']]\n",
    "\n",
    "# 2) 범주형 인코딩: 농장아이디, 개체번호\n",
    "cat_feats = ['농장아이디','개체번호']\n",
    "te = TargetEncoder(cols=cat_feats)\n",
    "X = te.fit_transform(X, y)\n",
    "\n",
    "# 3) Train/Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 4) 개별 모델 정의\n",
    "rf  = RandomForestRegressor(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "xgb = XGBRegressor(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "lgb = LGBMRegressor(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "\n",
    "# 5) 개별 모델 학습\n",
    "rf.fit(X_train, y_train)\n",
    "xgb.fit(X_train, y_train)\n",
    "lgb.fit(X_train, y_train)\n",
    "\n",
    "# 6) Voting 앙상블\n",
    "voting = VotingRegressor([('rf', rf), ('xgb', xgb), ('lgb', lgb)])\n",
    "voting.fit(X_train, y_train)\n",
    "\n",
    "# 7) Stacking 앙상블 (메타모델: Ridge)\n",
    "stack = StackingRegressor(\n",
    "    estimators=[('rf', rf), ('xgb', xgb), ('lgb', lgb)],\n",
    "    final_estimator=Ridge(),\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "stack.fit(X_train, y_train)\n",
    "\n",
    "# --- 8) 평가 예시 (mape 계산 로직 수정) ---\n",
    "for name, m in [\n",
    "    ('RF', rf), ('XGB', xgb), ('LGBM', lgb),\n",
    "    ('Voting', voting), ('Stacking', stack)\n",
    "]:\n",
    "    y_pred = m.predict(X_test)\n",
    "\n",
    "    rmse = root_mean_squared_error(y_test, y_pred)\n",
    "    r2   = r2_score(y_test, y_pred)\n",
    "    mae  = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    # 1) y_test가 0이 아닌 인덱스만 골라서 MAPE 계산\n",
    "    nonzero_mask = y_test != 0\n",
    "    mape = mean_absolute_percentage_error(\n",
    "        y_test[nonzero_mask],\n",
    "        y_pred[nonzero_mask]\n",
    "    ) * 100  # 비율 → 퍼센트\n",
    "\n",
    "    print(\n",
    "        f\"{name} \"\n",
    "        f\"RMSE: {rmse:.3f}, \"\n",
    "        f\"R²: {r2:.3f}, \"\n",
    "        f\"MAE: {mae:.3f}, \"\n",
    "        f\"MAPE: {mape:.2f}%\"\n",
    "    )\n",
    "\n",
    "# 9) 교차검증으로 과적합 체크\n",
    "print(\"\\n--- 교차검증 (5‑fold R²) & 과적합 정도 ---\")\n",
    "for name, m in [('RF', rf), ('XGB', xgb), ('LGBM', lgb),\n",
    "                ('Voting', voting), ('Stacking', stack)]:\n",
    "    cv_scores = cross_val_score(m, X_train, y_train, cv=5, scoring='r2', n_jobs=-1)\n",
    "    test_r2 = r2_score(y_test, m.predict(X_test))\n",
    "    print(f\"{name} CV R2: {cv_scores.mean():.3f} ± {cv_scores.std():.3f}, Overfit: {abs(cv_scores.mean() - test_r2):.3f}\")\n",
    "\n",
    "# 10) 피처 중요도 분석\n",
    "print(\"\\n--- 피처 중요도 순위 (RF / XGB / LGBM) ---\")\n",
    "feature_names = X_train.columns\n",
    "for name, m in [('RF', rf), ('XGB', xgb), ('LGBM', lgb)]:\n",
    "    importance = m.feature_importances_\n",
    "    fi_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': importance\n",
    "    }).sort_values('Importance', ascending=False).reset_index(drop=True)\n",
    "    print(f\"\\n{name} Feature Importances:\\n\", fi_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9009d49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000322 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 891\n",
      "[LightGBM] [Info] Number of data points in the train set: 16840, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 11.778979\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000209 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 891\n",
      "[LightGBM] [Info] Number of data points in the train set: 16840, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 11.778979\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000314 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 891\n",
      "[LightGBM] [Info] Number of data points in the train set: 16840, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 11.778979\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003484 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 886\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 11\n",
      "[LightGBM] [Info] [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014178 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Auto-choosing col-wise multi-threading, the overhead of testing was 0.013710 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 882\n",
      "[LightGBM] [Info] Total Bins 889\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003129 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 11\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 11\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 11.798248\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027948 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 887\n",
      "[LightGBM] [Info] Start training from score 11.775683\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 11.769151\n",
      "[LightGBM] [Info] Start training from score 11.764326\n",
      "[LightGBM] [Info] Start training from score 11.787485\n",
      "RF RMSE: 1.423, R²: 0.845, MAE: 1.002, MAPE: 9.31%\n",
      "XGB RMSE: 1.358, R²: 0.859, MAE: 0.997, MAPE: 9.20%\n",
      "LGBM RMSE: 1.388, R²: 0.853, MAE: 1.043, MAPE: 9.53%\n",
      "Voting RMSE: 1.325, R²: 0.866, MAE: 0.967, MAPE: 8.92%\n",
      "Stacking RMSE: 1.317, R²: 0.868, MAE: 0.961, MAPE: 8.81%\n",
      "\n",
      "--- 교차검증 (5‑fold R²) & 과적합 정도 ---\n",
      "RF CV R2: 0.834 ± 0.003, Overfit: 0.011\n",
      "XGB CV R2: 0.848 ± 0.005, Overfit: 0.012\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000760 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 889\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 11.769151\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000514 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 882\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 11\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005937 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 887\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 11.775683\n",
      "[LightGBM] [Info] Start training from score 11.787485\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001193 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 11.764326\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000662 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 886\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 11.798248\n",
      "LGBM CV R2: 0.845 ± 0.005, Overfit: 0.008\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000336 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 882\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 11.775683\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000885 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 887\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 11.787485\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000788 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 889\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 11.769151\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000444 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 11.764326\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000522 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 886\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 11.798248\n",
      "Voting CV R2: 0.857 ± 0.003, Overfit: 0.009\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009284 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 887\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007810 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 882\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 11\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 11.787485\n",
      "[LightGBM] [Info] Start training from score 11.775683\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028072 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 889\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 11.769151\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008483 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000584 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 886\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 11\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 11.798248\n",
      "[LightGBM] [Info] Start training from score 11.764326\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000961 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 884\n",
      "[LightGBM] [Info] Number of data points in the train set: 10777, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 11.808295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016740 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 880\n",
      "[LightGBM] [Info] Number of data points in the train set: 10777, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 11.798089\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003459 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 887\n",
      "[LightGBM] [Info] Number of data points in the train set: 10777, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 11.771922\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002069 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 10777, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 11.765890\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000917 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 878\n",
      "[LightGBM] [Info] Number of data points in the train set: 10777, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 11.794841\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000706 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 884\n",
      "[LightGBM] [Info] Number of data points in the train set: 10777, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 11.785469\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000642 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 881\n",
      "[LightGBM] [Info] Number of data points in the train set: 10777, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 11.811636\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014457 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 10777, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 11.767468\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007681 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 884\n",
      "[LightGBM] [Info] Number of data points in the train set: 10777, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 11.769231\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001770 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 887\n",
      "[LightGBM] [Info] Number of data points in the train set: 10777, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 11.775262\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000618 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 887\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 11.764799\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001095 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 894\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 11.793839\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000948 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 886\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 11.750046\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000570 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 891\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 11.752088\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000525 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 889\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 11.751438\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000442 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 884\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 11.784747\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000446 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 886\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 11.782520\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000628 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 889\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 11.761830\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000181 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 883\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 11.769994\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000676 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 889\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 11.756448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000736 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 11.807571\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000786 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 11.794953\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000977 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 886\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 11.784654\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006911 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 886\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 11.778623\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001213 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 879\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 11.792819\n",
      "Stacking CV R2: 0.858 ± 0.004, Overfit: 0.010\n",
      "\n",
      "--- 피처 중요도 순위 (RF / XGB / LGBM) ---\n",
      "\n",
      "RF Feature Importances:\n",
      "       Feature  Importance\n",
      "0        개체번호    0.567749\n",
      "1        착유시간    0.102489\n",
      "2   P/F_ratio    0.089942\n",
      "3     공기흐름_비율    0.089114\n",
      "4          온도    0.037609\n",
      "5         측정일    0.032208\n",
      "6        착유회차    0.019543\n",
      "7          나이    0.018601\n",
      "8       착유시간대    0.016533\n",
      "9    개체별_착유일수    0.013120\n",
      "10      농장아이디    0.013007\n",
      "11       혈액흐름    0.000085\n",
      "\n",
      "XGB Feature Importances:\n",
      "       Feature  Importance\n",
      "0        개체번호    0.376401\n",
      "1        착유시간    0.185585\n",
      "2       착유시간대    0.084548\n",
      "3        착유회차    0.071694\n",
      "4     공기흐름_비율    0.055776\n",
      "5       농장아이디    0.051975\n",
      "6   P/F_ratio    0.046710\n",
      "7    개체별_착유일수    0.040627\n",
      "8          나이    0.039053\n",
      "9          온도    0.027432\n",
      "10        측정일    0.014392\n",
      "11       혈액흐름    0.005805\n",
      "\n",
      "LGBM Feature Importances:\n",
      "       Feature  Importance\n",
      "0     공기흐름_비율        1095\n",
      "1        개체번호        1078\n",
      "2   P/F_ratio         926\n",
      "3        착유시간         749\n",
      "4         측정일         472\n",
      "5          온도         459\n",
      "6          나이         284\n",
      "7    개체별_착유일수         268\n",
      "8       농장아이디         239\n",
      "9       착유시간대         229\n",
      "10       착유회차         201\n",
      "11       혈액흐름           0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor, VotingRegressor, StackingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "# 1) 데이터 준비\n",
    "y = df_clean['착유량']\n",
    "\n",
    "# drop target & 불필요 컬럼\n",
    "X = df_clean[[\"개체번호\",\"공기흐름_비율\",\"P/F_ratio\",\"개체별_착유일수\",\"측정일\",\"농장아이디\",'착유시간','착유회차', '착유시간대', '온도', '나이', '혈액흐름']]\n",
    "\n",
    "# 2) 범주형 인코딩: 농장아이디, 개체번호\n",
    "cat_feats = ['농장아이디','개체번호']\n",
    "te = TargetEncoder(cols=cat_feats)\n",
    "X = te.fit_transform(X, y)\n",
    "\n",
    "# 3) Train/Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 4) 개별 모델 정의\n",
    "rf  = RandomForestRegressor(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "xgb = XGBRegressor(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "lgb = LGBMRegressor(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "\n",
    "# 5) 개별 모델 학습\n",
    "rf.fit(X_train, y_train)\n",
    "xgb.fit(X_train, y_train)\n",
    "lgb.fit(X_train, y_train)\n",
    "\n",
    "# 6) Voting 앙상블\n",
    "voting = VotingRegressor([('rf', rf), ('xgb', xgb), ('lgb', lgb)])\n",
    "voting.fit(X_train, y_train)\n",
    "\n",
    "# 7) Stacking 앙상블 (메타모델: Ridge)\n",
    "stack = StackingRegressor(\n",
    "    estimators=[('rf', rf), ('xgb', xgb), ('lgb', lgb)],\n",
    "    final_estimator=Ridge(),\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "stack.fit(X_train, y_train)\n",
    "\n",
    "# --- 8) 평가 예시 (mape 계산 로직 수정) ---\n",
    "for name, m in [\n",
    "    ('RF', rf), ('XGB', xgb), ('LGBM', lgb),\n",
    "    ('Voting', voting), ('Stacking', stack)\n",
    "]:\n",
    "    y_pred = m.predict(X_test)\n",
    "\n",
    "    rmse = root_mean_squared_error(y_test, y_pred)\n",
    "    r2   = r2_score(y_test, y_pred)\n",
    "    mae  = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    # 1) y_test가 0이 아닌 인덱스만 골라서 MAPE 계산\n",
    "    nonzero_mask = y_test != 0\n",
    "    mape = mean_absolute_percentage_error(\n",
    "        y_test[nonzero_mask],\n",
    "        y_pred[nonzero_mask]\n",
    "    ) * 100  # 비율 → 퍼센트\n",
    "\n",
    "    print(\n",
    "        f\"{name} \"\n",
    "        f\"RMSE: {rmse:.3f}, \"\n",
    "        f\"R²: {r2:.3f}, \"\n",
    "        f\"MAE: {mae:.3f}, \"\n",
    "        f\"MAPE: {mape:.2f}%\"\n",
    "    )\n",
    "\n",
    "# 9) 교차검증으로 과적합 체크\n",
    "print(\"\\n--- 교차검증 (5‑fold R²) & 과적합 정도 ---\")\n",
    "for name, m in [('RF', rf), ('XGB', xgb), ('LGBM', lgb),\n",
    "                ('Voting', voting), ('Stacking', stack)]:\n",
    "    cv_scores = cross_val_score(m, X_train, y_train, cv=5, scoring='r2', n_jobs=-1)\n",
    "    test_r2 = r2_score(y_test, m.predict(X_test))\n",
    "    print(f\"{name} CV R2: {cv_scores.mean():.3f} ± {cv_scores.std():.3f}, Overfit: {abs(cv_scores.mean() - test_r2):.3f}\")\n",
    "\n",
    "# 10) 피처 중요도 분석\n",
    "print(\"\\n--- 피처 중요도 순위 (RF / XGB / LGBM) ---\")\n",
    "feature_names = X_train.columns\n",
    "for name, m in [('RF', rf), ('XGB', xgb), ('LGBM', lgb)]:\n",
    "    importance = m.feature_importances_\n",
    "    fi_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': importance\n",
    "    }).sort_values('Importance', ascending=False).reset_index(drop=True)\n",
    "    print(f\"\\n{name} Feature Importances:\\n\", fi_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74d9f23e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['농장아이디', '개체번호', '착유량', '착유시작일시', '착유종료일시', '착유회차', '전도도', '혈액흐름', '온도',\n",
       "       '유지방', '유단백', '공기흐름', '착유시간', '나이', '측정일', '개체별_일일착유량', '개체별_착유일수',\n",
       "       '착유시간대', 'P/F_ratio', '착유효율', '개체별_전도도율', '공기흐름_비율'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3333a331",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['개체별_일별착유횟수'] = (\n",
    "    df_clean\n",
    "      .groupby(['개체번호','측정일'])            # 개체번호+측정일별로\n",
    "      ['착유회차']                             # 아무 칼럼 써도 되는데, 착유회차로\n",
    "      .transform('count')                     # 등장 횟수를 세어서\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11499c13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>농장아이디</th>\n",
       "      <th>개체번호</th>\n",
       "      <th>착유량</th>\n",
       "      <th>착유시작일시</th>\n",
       "      <th>착유종료일시</th>\n",
       "      <th>착유회차</th>\n",
       "      <th>전도도</th>\n",
       "      <th>혈액흐름</th>\n",
       "      <th>온도</th>\n",
       "      <th>유지방</th>\n",
       "      <th>...</th>\n",
       "      <th>나이</th>\n",
       "      <th>측정일</th>\n",
       "      <th>개체별_일일착유량</th>\n",
       "      <th>개체별_착유일수</th>\n",
       "      <th>착유시간대</th>\n",
       "      <th>P/F_ratio</th>\n",
       "      <th>착유효율</th>\n",
       "      <th>개체별_전도도율</th>\n",
       "      <th>공기흐름_비율</th>\n",
       "      <th>개체별_일별착유횟수</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20278</td>\n",
       "      <td>20130816010079</td>\n",
       "      <td>16</td>\n",
       "      <td>2021-09-01 06:52:00</td>\n",
       "      <td>2021-09-01 07:04:00</td>\n",
       "      <td>1</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0</td>\n",
       "      <td>39.9</td>\n",
       "      <td>4.1</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>0.804878</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>7.042857</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20278</td>\n",
       "      <td>20130816010079</td>\n",
       "      <td>17</td>\n",
       "      <td>2021-09-01 17:02:00</td>\n",
       "      <td>2021-09-01 17:11:00</td>\n",
       "      <td>2</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0</td>\n",
       "      <td>40.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>1.888889</td>\n",
       "      <td>7.042857</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20278</td>\n",
       "      <td>20130816010079</td>\n",
       "      <td>14</td>\n",
       "      <td>2021-09-02 01:41:00</td>\n",
       "      <td>2021-09-02 01:51:00</td>\n",
       "      <td>1</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0</td>\n",
       "      <td>39.9</td>\n",
       "      <td>4.8</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>7.042857</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20278</td>\n",
       "      <td>20130816010079</td>\n",
       "      <td>10</td>\n",
       "      <td>2021-09-02 07:28:00</td>\n",
       "      <td>2021-09-02 07:36:00</td>\n",
       "      <td>2</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0</td>\n",
       "      <td>39.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>7.042857</td>\n",
       "      <td>0.212500</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20278</td>\n",
       "      <td>20130816010079</td>\n",
       "      <td>11</td>\n",
       "      <td>2021-09-02 14:33:00</td>\n",
       "      <td>2021-09-02 14:45:00</td>\n",
       "      <td>3</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>7.042857</td>\n",
       "      <td>0.108333</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21653</th>\n",
       "      <td>20264</td>\n",
       "      <td>20191027020116</td>\n",
       "      <td>9</td>\n",
       "      <td>2021-09-25 01:29:00</td>\n",
       "      <td>2021-09-25 01:35:00</td>\n",
       "      <td>1</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0</td>\n",
       "      <td>38.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>29</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>6.420455</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21654</th>\n",
       "      <td>20264</td>\n",
       "      <td>20191027020116</td>\n",
       "      <td>9</td>\n",
       "      <td>2021-09-25 09:15:00</td>\n",
       "      <td>2021-09-25 09:21:00</td>\n",
       "      <td>2</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0</td>\n",
       "      <td>39.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>29</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>1.178571</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>6.420455</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21655</th>\n",
       "      <td>20264</td>\n",
       "      <td>20191027020116</td>\n",
       "      <td>11</td>\n",
       "      <td>2021-09-25 19:28:00</td>\n",
       "      <td>2021-09-25 19:35:00</td>\n",
       "      <td>3</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0</td>\n",
       "      <td>39.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>29</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>1.360000</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>6.420455</td>\n",
       "      <td>0.557143</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21656</th>\n",
       "      <td>20264</td>\n",
       "      <td>20191027020116</td>\n",
       "      <td>13</td>\n",
       "      <td>2021-09-26 08:22:00</td>\n",
       "      <td>2021-09-26 08:29:00</td>\n",
       "      <td>1</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0</td>\n",
       "      <td>39.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>1.214286</td>\n",
       "      <td>1.857143</td>\n",
       "      <td>6.420455</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21657</th>\n",
       "      <td>20264</td>\n",
       "      <td>20191027020116</td>\n",
       "      <td>13</td>\n",
       "      <td>2021-09-26 19:42:00</td>\n",
       "      <td>2021-09-26 19:49:00</td>\n",
       "      <td>2</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0</td>\n",
       "      <td>39.6</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>1.360000</td>\n",
       "      <td>1.857143</td>\n",
       "      <td>6.420455</td>\n",
       "      <td>0.528571</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21050 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       농장아이디            개체번호  착유량              착유시작일시              착유종료일시  \\\n",
       "0      20278  20130816010079   16 2021-09-01 06:52:00 2021-09-01 07:04:00   \n",
       "1      20278  20130816010079   17 2021-09-01 17:02:00 2021-09-01 17:11:00   \n",
       "2      20278  20130816010079   14 2021-09-02 01:41:00 2021-09-02 01:51:00   \n",
       "3      20278  20130816010079   10 2021-09-02 07:28:00 2021-09-02 07:36:00   \n",
       "4      20278  20130816010079   11 2021-09-02 14:33:00 2021-09-02 14:45:00   \n",
       "...      ...             ...  ...                 ...                 ...   \n",
       "21653  20264  20191027020116    9 2021-09-25 01:29:00 2021-09-25 01:35:00   \n",
       "21654  20264  20191027020116    9 2021-09-25 09:15:00 2021-09-25 09:21:00   \n",
       "21655  20264  20191027020116   11 2021-09-25 19:28:00 2021-09-25 19:35:00   \n",
       "21656  20264  20191027020116   13 2021-09-26 08:22:00 2021-09-26 08:29:00   \n",
       "21657  20264  20191027020116   13 2021-09-26 19:42:00 2021-09-26 19:49:00   \n",
       "\n",
       "       착유회차  전도도  혈액흐름    온도  유지방  ...  나이  측정일  개체별_일일착유량  개체별_착유일수  착유시간대  \\\n",
       "0         1  7.1     0  39.9  4.1  ...   8    1         33        26      2   \n",
       "1         2  6.8     0  40.2  4.5  ...   8    1         33        26      3   \n",
       "2         1  6.8     0  39.9  4.8  ...   8    2         35        26      1   \n",
       "3         2  6.8     0  39.6  5.0  ...   8    2         35        26      2   \n",
       "4         3  6.8     0  40.0  4.7  ...   8    2         35        26      3   \n",
       "...     ...  ...   ...   ...  ...  ...  ..  ...        ...       ...    ...   \n",
       "21653     1  6.2     0  38.8  3.3  ...   1   25         29        19      1   \n",
       "21654     2  6.4     0  39.2  2.8  ...   1   25         29        19      2   \n",
       "21655     3  6.4     0  39.5  2.5  ...   1   25         29        19      4   \n",
       "21656     1  6.2     0  39.4  2.8  ...   1   26         26        19      2   \n",
       "21657     2  6.4     0  39.6  2.5  ...   1   26         26        19      4   \n",
       "\n",
       "       P/F_ratio      착유효율  개체별_전도도율   공기흐름_비율  개체별_일별착유횟수  \n",
       "0       0.804878  1.333333  7.042857  0.125000           2  \n",
       "1       0.711111  1.888889  7.042857  0.233333           2  \n",
       "2       0.645833  1.400000  7.042857  0.190000           3  \n",
       "3       0.620000  1.250000  7.042857  0.212500           3  \n",
       "4       0.680851  0.916667  7.042857  0.108333           3  \n",
       "...          ...       ...       ...       ...         ...  \n",
       "21653   1.000000  1.500000  6.420455  0.616667           3  \n",
       "21654   1.178571  1.500000  6.420455  0.616667           3  \n",
       "21655   1.360000  1.571429  6.420455  0.557143           3  \n",
       "21656   1.214286  1.857143  6.420455  0.571429           2  \n",
       "21657   1.360000  1.857143  6.420455  0.528571           2  \n",
       "\n",
       "[21050 rows x 23 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2bf7923a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000538 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 897\n",
      "[LightGBM] [Info] Number of data points in the train set: 16840, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 11.778979\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000393 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 897\n",
      "[LightGBM] [Info] Number of data points in the train set: 16840, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 11.778979\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009098 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 897\n",
      "[LightGBM] [Info] Number of data points in the train set: 16840, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 11.778979\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002637 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000987 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002123 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001211 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Total Bins 893\n",
      "[LightGBM] [Info] Total Bins 896\n",
      "[LightGBM] [Info] Total Bins 892\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001052 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 12\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 12\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 12\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 12\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 11.775683\n",
      "[LightGBM] [Info] Start training from score 11.798248\n",
      "[LightGBM] [Info] Start training from score 11.787485\n",
      "[LightGBM] [Info] Start training from score 11.769151\n",
      "[LightGBM] [Info] Start training from score 11.764326\n",
      "RF RMSE: 1.426, R²: 0.845, MAE: 1.004, MAPE: 9.34%\n",
      "XGB RMSE: 1.346, R²: 0.862, MAE: 0.995, MAPE: 9.16%\n",
      "LGBM RMSE: 1.380, R²: 0.855, MAE: 1.032, MAPE: 9.41%\n",
      "Voting RMSE: 1.316, R²: 0.868, MAE: 0.966, MAPE: 8.90%\n",
      "Stacking RMSE: 1.308, R²: 0.869, MAE: 0.964, MAPE: 8.82%\n",
      "\n",
      "--- 교차검증 (5‑fold R²) & 과적합 정도 ---\n",
      "RF CV R2: 0.831 ± 0.006, Overfit: 0.014\n",
      "XGB CV R2: 0.850 ± 0.006, Overfit: 0.012\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000258 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 11.769151\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000896 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 896\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 11.764326\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000743 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 893\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 11.787485\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000746 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 892\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 11.798248\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000686 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 11.775683\n",
      "LGBM CV R2: 0.846 ± 0.006, Overfit: 0.008\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000385 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 11.775683\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000442 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 896\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 11.764326\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000537 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 11.769151\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001013 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 892\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 11.798248\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000583 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 893\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 11.787485\n",
      "Voting CV R2: 0.857 ± 0.005, Overfit: 0.011\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001879 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 893\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 11.787485\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005382 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 11.769151\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007237 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 896\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 11.764326\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000700 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 892\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 11.798248\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000809 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 11.775683\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003987 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 884\n",
      "[LightGBM] [Info] Number of data points in the train set: 10777, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 11.794841\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000394 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 10777, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 11.808295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004473 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 886\n",
      "[LightGBM] [Info] Number of data points in the train set: 10777, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 11.798089\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000500 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 893\n",
      "[LightGBM] [Info] Number of data points in the train set: 10777, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 11.771922\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000306 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 894\n",
      "[LightGBM] [Info] Number of data points in the train set: 10777, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 11.765890\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001078 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 894\n",
      "[LightGBM] [Info] Number of data points in the train set: 10777, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 11.767468\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001950 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 10777, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 11.785469\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001866 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 887\n",
      "[LightGBM] [Info] Number of data points in the train set: 10777, number of used features: 12\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000621 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 893\n",
      "[LightGBM] [Info] Number of data points in the train set: 10777, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 11.811636\n",
      "[LightGBM] [Info] Start training from score 11.775262\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000272 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 10777, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 11.769231\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006551 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 892\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 11.750046\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000437 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 893\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 11.764799\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000891 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 11.751438\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000704 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 900\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 11.793839\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000441 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 897\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 11.752088\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000474 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 889\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 11.769994\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001676 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 890\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 11.784747\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004475 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 892\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 11.782520\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000575 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 11.761830\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000679 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 11.756448\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000701 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 885\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 11.792819\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000484 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 891\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 11.807571\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000719 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 892\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 11.784654\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000772 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 891\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 11.794953\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000752 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 892\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 11.778623\n",
      "Stacking CV R2: 0.858 ± 0.005, Overfit: 0.011\n",
      "\n",
      "--- 피처 중요도 순위 (RF / XGB / LGBM) ---\n",
      "\n",
      "RF Feature Importances:\n",
      "        Feature  Importance\n",
      "0         개체번호    0.566054\n",
      "1         착유시간    0.096702\n",
      "2    P/F_ratio    0.090390\n",
      "3      공기흐름_비율    0.080492\n",
      "4           온도    0.034758\n",
      "5   개체별_일별착유횟수    0.033549\n",
      "6          측정일    0.030839\n",
      "7           나이    0.016829\n",
      "8        착유시간대    0.013945\n",
      "9        농장아이디    0.012637\n",
      "10        착유회차    0.012063\n",
      "11    개체별_착유일수    0.011691\n",
      "12        혈액흐름    0.000051\n",
      "\n",
      "XGB Feature Importances:\n",
      "        Feature  Importance\n",
      "0         개체번호    0.351434\n",
      "1         착유시간    0.181061\n",
      "2   개체별_일별착유횟수    0.099931\n",
      "3        착유시간대    0.057447\n",
      "4      공기흐름_비율    0.048905\n",
      "5         착유회차    0.047718\n",
      "6        농장아이디    0.047647\n",
      "7    P/F_ratio    0.044579\n",
      "8           나이    0.040304\n",
      "9     개체별_착유일수    0.033924\n",
      "10          온도    0.023877\n",
      "11         측정일    0.013179\n",
      "12        혈액흐름    0.009993\n",
      "\n",
      "LGBM Feature Importances:\n",
      "        Feature  Importance\n",
      "0      공기흐름_비율        1100\n",
      "1         개체번호        1098\n",
      "2    P/F_ratio         861\n",
      "3         착유시간         693\n",
      "4          측정일         454\n",
      "5           온도         411\n",
      "6           나이         286\n",
      "7        농장아이디         280\n",
      "8   개체별_일별착유횟수         244\n",
      "9     개체별_착유일수         229\n",
      "10       착유시간대         174\n",
      "11        착유회차         170\n",
      "12        혈액흐름           0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor, VotingRegressor, StackingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "# 1) 데이터 준비\n",
    "y = df_clean['착유량']\n",
    "\n",
    "# drop target & 불필요 컬럼\n",
    "X = df_clean[[\"개체번호\",\"공기흐름_비율\",\"P/F_ratio\",\"개체별_착유일수\",\"측정일\",\"농장아이디\",'착유시간','착유회차', '착유시간대', '온도', '나이', '혈액흐름', '개체별_일별착유횟수']]\n",
    "\n",
    "# 2) 범주형 인코딩: 농장아이디, 개체번호\n",
    "cat_feats = ['농장아이디','개체번호']\n",
    "te = TargetEncoder(cols=cat_feats)\n",
    "X = te.fit_transform(X, y)\n",
    "\n",
    "# 3) Train/Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 4) 개별 모델 정의\n",
    "rf  = RandomForestRegressor(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "xgb = XGBRegressor(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "lgb = LGBMRegressor(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "\n",
    "# 5) 개별 모델 학습\n",
    "rf.fit(X_train, y_train)\n",
    "xgb.fit(X_train, y_train)\n",
    "lgb.fit(X_train, y_train)\n",
    "\n",
    "# 6) Voting 앙상블\n",
    "voting = VotingRegressor([('rf', rf), ('xgb', xgb), ('lgb', lgb)])\n",
    "voting.fit(X_train, y_train)\n",
    "\n",
    "# 7) Stacking 앙상블 (메타모델: Ridge)\n",
    "stack = StackingRegressor(\n",
    "    estimators=[('rf', rf), ('xgb', xgb), ('lgb', lgb)],\n",
    "    final_estimator=Ridge(),\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "stack.fit(X_train, y_train)\n",
    "\n",
    "# --- 8) 평가 예시 (mape 계산 로직 수정) ---\n",
    "for name, m in [\n",
    "    ('RF', rf), ('XGB', xgb), ('LGBM', lgb),\n",
    "    ('Voting', voting), ('Stacking', stack)\n",
    "]:\n",
    "    y_pred = m.predict(X_test)\n",
    "\n",
    "    rmse = root_mean_squared_error(y_test, y_pred)\n",
    "    r2   = r2_score(y_test, y_pred)\n",
    "    mae  = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    # 1) y_test가 0이 아닌 인덱스만 골라서 MAPE 계산\n",
    "    nonzero_mask = y_test != 0\n",
    "    mape = mean_absolute_percentage_error(\n",
    "        y_test[nonzero_mask],\n",
    "        y_pred[nonzero_mask]\n",
    "    ) * 100  # 비율 → 퍼센트\n",
    "\n",
    "    print(\n",
    "        f\"{name} \"\n",
    "        f\"RMSE: {rmse:.3f}, \"\n",
    "        f\"R²: {r2:.3f}, \"\n",
    "        f\"MAE: {mae:.3f}, \"\n",
    "        f\"MAPE: {mape:.2f}%\"\n",
    "    )\n",
    "\n",
    "# 9) 교차검증으로 과적합 체크\n",
    "print(\"\\n--- 교차검증 (5‑fold R²) & 과적합 정도 ---\")\n",
    "for name, m in [('RF', rf), ('XGB', xgb), ('LGBM', lgb),\n",
    "                ('Voting', voting), ('Stacking', stack)]:\n",
    "    cv_scores = cross_val_score(m, X_train, y_train, cv=5, scoring='r2', n_jobs=-1)\n",
    "    test_r2 = r2_score(y_test, m.predict(X_test))\n",
    "    print(f\"{name} CV R2: {cv_scores.mean():.3f} ± {cv_scores.std():.3f}, Overfit: {abs(cv_scores.mean() - test_r2):.3f}\")\n",
    "\n",
    "# 10) 피처 중요도 분석\n",
    "print(\"\\n--- 피처 중요도 순위 (RF / XGB / LGBM) ---\")\n",
    "feature_names = X_train.columns\n",
    "for name, m in [('RF', rf), ('XGB', xgb), ('LGBM', lgb)]:\n",
    "    importance = m.feature_importances_\n",
    "    fi_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': importance\n",
    "    }).sort_values('Importance', ascending=False).reset_index(drop=True)\n",
    "    print(f\"\\n{name} Feature Importances:\\n\", fi_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "343a82ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000281 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 974\n",
      "[LightGBM] [Info] Number of data points in the train set: 16840, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 11.778979\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000190 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 974\n",
      "[LightGBM] [Info] Number of data points in the train set: 16840, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 11.778979\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001347 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 974\n",
      "[LightGBM] [Info] Number of data points in the train set: 16840, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 11.778979\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000227 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 964\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 11.775683\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000196 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 972\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 11.764326\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000791 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 968\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 11.798248\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000434 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 971\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 11.769151\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000550 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 968\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 11.787485\n",
      "RF RMSE: 1.434, R²: 0.843, MAE: 1.007, MAPE: 9.39%\n",
      "XGB RMSE: 1.346, R²: 0.862, MAE: 1.000, MAPE: 9.27%\n",
      "LGBM RMSE: 1.375, R²: 0.856, MAE: 1.028, MAPE: 9.42%\n",
      "Voting RMSE: 1.318, R²: 0.867, MAE: 0.970, MAPE: 8.98%\n",
      "Stacking RMSE: 1.309, R²: 0.869, MAE: 0.969, MAPE: 8.92%\n",
      "\n",
      "--- 교차검증 (5‑fold R²) & 과적합 정도 ---\n",
      "RF CV R2: 0.829 ± 0.005, Overfit: 0.014\n",
      "XGB CV R2: 0.850 ± 0.006, Overfit: 0.012\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000538 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 968\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000854 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 972\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 14\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 11.764326\n",
      "[LightGBM] [Info] Start training from score 11.787485\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001109 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 968\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 11.798248\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000441 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 971\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 11.769151\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000196 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 964\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 11.775683\n",
      "LGBM CV R2: 0.847 ± 0.006, Overfit: 0.009\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000344 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 964\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 11.775683\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000491 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 972\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 11.764326\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.062361 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 968\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 11.798248\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000343 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 971\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 11.769151\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000956 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 968\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 11.787485\n",
      "Voting CV R2: 0.857 ± 0.005, Overfit: 0.011\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001300 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 968\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 11.787485\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035505 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 971\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 11.769151\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002616 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 964\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 11.775683\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001092 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 972\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 11.764326\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000811 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 968\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 11.798248\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002551 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 960\n",
      "[LightGBM] [Info] Number of data points in the train set: 10777, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 11.798089\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001640 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 958\n",
      "[LightGBM] [Info] Number of data points in the train set: 10777, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 11.794841\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001982 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002295 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 965\n",
      "[LightGBM] [Info] Total Bins 967\n",
      "[LightGBM] [Info] Number of data points in the train set: 10777, number of used features: 14\n",
      "[LightGBM] [Info] Number of data points in the train set: 10777, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 11.771922\n",
      "[LightGBM] [Info] Start training from score 11.808295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001035 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 968\n",
      "[LightGBM] [Info] Number of data points in the train set: 10777, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 11.765890\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000322 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 968\n",
      "[LightGBM] [Info] Number of data points in the train set: 10777, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 11.775262\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000741 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 969\n",
      "[LightGBM] [Info] Number of data points in the train set: 10777, number of used features: 14\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000729 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 963\n",
      "[LightGBM] [Info] [LightGBM] [Info] Number of data points in the train set: 10777, number of used features: 14\n",
      "Start training from score 11.767468\n",
      "[LightGBM] [Info] Start training from score 11.769231\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000682 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 965\n",
      "[LightGBM] [Info] Number of data points in the train set: 10777, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 11.785469\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000676 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 961\n",
      "[LightGBM] [Info] Number of data points in the train set: 10777, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 11.811636\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000509 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 970\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 11.751438\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000287 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 967\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 11.764799\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000691 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 976\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 11.793839\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000867 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 972\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 11.752088\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000616 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 966\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 11.750046\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000925 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 969\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 11.756448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000867 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 964\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 11.784747\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000395 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 967\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 11.782520\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000453 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 964\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 11.769994\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001100 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 970\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 11.761830\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000826 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 966\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 11.778623\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000492 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 965\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 11.807571\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002694 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 966\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 11.794953\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000548 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 960\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 11.792819\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000683 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 968\n",
      "[LightGBM] [Info] Number of data points in the train set: 10778, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 11.784654\n",
      "Stacking CV R2: 0.858 ± 0.006, Overfit: 0.011\n",
      "\n",
      "--- 피처 중요도 순위 (RF / XGB / LGBM) ---\n",
      "\n",
      "RF Feature Importances:\n",
      "        Feature  Importance\n",
      "0         개체번호    0.562467\n",
      "1         착유시간    0.094503\n",
      "2      공기흐름_비율    0.074431\n",
      "3    P/F_ratio    0.064223\n",
      "4          유지방    0.034900\n",
      "5   개체별_일별착유횟수    0.032356\n",
      "6           온도    0.031791\n",
      "7          측정일    0.027616\n",
      "8          유단백    0.018933\n",
      "9           나이    0.014912\n",
      "10       착유시간대    0.012474\n",
      "11        착유회차    0.011272\n",
      "12       농장아이디    0.010438\n",
      "13    개체별_착유일수    0.009645\n",
      "14        혈액흐름    0.000038\n",
      "\n",
      "XGB Feature Importances:\n",
      "        Feature  Importance\n",
      "0         개체번호    0.338115\n",
      "1         착유시간    0.164457\n",
      "2   개체별_일별착유횟수    0.092611\n",
      "3        농장아이디    0.047794\n",
      "4        착유시간대    0.046295\n",
      "5      공기흐름_비율    0.043282\n",
      "6         혈액흐름    0.042731\n",
      "7         착유회차    0.040534\n",
      "8    P/F_ratio    0.038978\n",
      "9           나이    0.031785\n",
      "10         유지방    0.031437\n",
      "11    개체별_착유일수    0.025695\n",
      "12          온도    0.022495\n",
      "13         유단백    0.021540\n",
      "14         측정일    0.012250\n",
      "\n",
      "LGBM Feature Importances:\n",
      "        Feature  Importance\n",
      "0         개체번호         998\n",
      "1      공기흐름_비율         993\n",
      "2         착유시간         651\n",
      "3    P/F_ratio         599\n",
      "4           온도         419\n",
      "5          측정일         395\n",
      "6          유지방         330\n",
      "7          유단백         320\n",
      "8           나이         276\n",
      "9        농장아이디         253\n",
      "10  개체별_일별착유횟수         230\n",
      "11    개체별_착유일수         210\n",
      "12        착유회차         172\n",
      "13       착유시간대         154\n",
      "14        혈액흐름           0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor, VotingRegressor, StackingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "# 1) 데이터 준비\n",
    "y = df_clean['착유량']\n",
    "\n",
    "# drop target & 불필요 컬럼\n",
    "X = df_clean[[\"개체번호\",\"공기흐름_비율\",\"P/F_ratio\",\"개체별_착유일수\",\"측정일\",\"농장아이디\",'착유시간','착유회차', '착유시간대', '온도', '나이', '혈액흐름', '개체별_일별착유횟수', '유지방', '유단백']]\n",
    "\n",
    "# 2) 범주형 인코딩: 농장아이디, 개체번호\n",
    "cat_feats = ['농장아이디','개체번호']\n",
    "te = TargetEncoder(cols=cat_feats)\n",
    "X = te.fit_transform(X, y)\n",
    "\n",
    "# 3) Train/Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 4) 개별 모델 정의\n",
    "rf  = RandomForestRegressor(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "xgb = XGBRegressor(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "lgb = LGBMRegressor(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "\n",
    "# 5) 개별 모델 학습\n",
    "rf.fit(X_train, y_train)\n",
    "xgb.fit(X_train, y_train)\n",
    "lgb.fit(X_train, y_train)\n",
    "\n",
    "# 6) Voting 앙상블\n",
    "voting = VotingRegressor([('rf', rf), ('xgb', xgb), ('lgb', lgb)])\n",
    "voting.fit(X_train, y_train)\n",
    "\n",
    "# 7) Stacking 앙상블 (메타모델: Ridge)\n",
    "stack = StackingRegressor(\n",
    "    estimators=[('rf', rf), ('xgb', xgb), ('lgb', lgb)],\n",
    "    final_estimator=Ridge(),\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "stack.fit(X_train, y_train)\n",
    "\n",
    "# --- 8) 평가 예시 (mape 계산 로직 수정) ---\n",
    "for name, m in [\n",
    "    ('RF', rf), ('XGB', xgb), ('LGBM', lgb),\n",
    "    ('Voting', voting), ('Stacking', stack)\n",
    "]:\n",
    "    y_pred = m.predict(X_test)\n",
    "\n",
    "    rmse = root_mean_squared_error(y_test, y_pred)\n",
    "    r2   = r2_score(y_test, y_pred)\n",
    "    mae  = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    # 1) y_test가 0이 아닌 인덱스만 골라서 MAPE 계산\n",
    "    nonzero_mask = y_test != 0\n",
    "    mape = mean_absolute_percentage_error(\n",
    "        y_test[nonzero_mask],\n",
    "        y_pred[nonzero_mask]\n",
    "    ) * 100  # 비율 → 퍼센트\n",
    "\n",
    "    print(\n",
    "        f\"{name} \"\n",
    "        f\"RMSE: {rmse:.3f}, \"\n",
    "        f\"R²: {r2:.3f}, \"\n",
    "        f\"MAE: {mae:.3f}, \"\n",
    "        f\"MAPE: {mape:.2f}%\"\n",
    "    )\n",
    "\n",
    "# 9) 교차검증으로 과적합 체크\n",
    "print(\"\\n--- 교차검증 (5‑fold R²) & 과적합 정도 ---\")\n",
    "for name, m in [('RF', rf), ('XGB', xgb), ('LGBM', lgb),\n",
    "                ('Voting', voting), ('Stacking', stack)]:\n",
    "    cv_scores = cross_val_score(m, X_train, y_train, cv=5, scoring='r2', n_jobs=-1)\n",
    "    test_r2 = r2_score(y_test, m.predict(X_test))\n",
    "    print(f\"{name} CV R2: {cv_scores.mean():.3f} ± {cv_scores.std():.3f}, Overfit: {abs(cv_scores.mean() - test_r2):.3f}\")\n",
    "\n",
    "# 10) 피처 중요도 분석\n",
    "print(\"\\n--- 피처 중요도 순위 (RF / XGB / LGBM) ---\")\n",
    "feature_names = X_train.columns\n",
    "for name, m in [('RF', rf), ('XGB', xgb), ('LGBM', lgb)]:\n",
    "    importance = m.feature_importances_\n",
    "    fi_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': importance\n",
    "    }).sort_values('Importance', ascending=False).reset_index(drop=True)\n",
    "    print(f\"\\n{name} Feature Importances:\\n\", fi_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "222ae05f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['농장아이디', '개체번호', '착유량', '착유시작일시', '착유종료일시', '착유회차', '전도도', '혈액흐름', '온도',\n",
       "       '유지방', '유단백', '공기흐름', '착유시간', '나이', '측정일', '개체별_일일착유량', '개체별_착유일수',\n",
       "       '착유시간대', 'P/F_ratio', '착유효율', '개체별_전도도율', '공기흐름_비율', '개체별_일별착유횟수',\n",
       "       'comp_pca'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "79bb28d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tabpy\n",
      "  Downloading tabpy-2.13.0.tar.gz (466 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m466.8/466.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting cloudpickle (from tabpy)\n",
      "  Downloading cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting configparser (from tabpy)\n",
      "  Downloading configparser-7.2.0-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting coverage (from tabpy)\n",
      "  Downloading coverage-7.10.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (8.9 kB)\n",
      "Collecting coveralls (from tabpy)\n",
      "  Downloading coveralls-4.0.1-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting docopt (from tabpy)\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting future (from tabpy)\n",
      "  Downloading future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting genson (from tabpy)\n",
      "  Downloading genson-1.3.0-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting hypothesis (from tabpy)\n",
      "  Downloading hypothesis-6.137.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting jsonschema (from tabpy)\n",
      "  Using cached jsonschema-4.25.0-py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting mock (from tabpy)\n",
      "  Downloading mock-5.2.0-py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting nltk (from tabpy)\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: numpy in /Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages (from tabpy) (2.3.2)\n",
      "Requirement already satisfied: pandas in /Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages (from tabpy) (2.3.1)\n",
      "Collecting pyopenssl (from tabpy)\n",
      "  Downloading pyopenssl-25.1.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting pytest (from tabpy)\n",
      "  Downloading pytest-8.4.1-py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting pytest-cov (from tabpy)\n",
      "  Downloading pytest_cov-6.2.1-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: requests in /Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages (from tabpy) (2.32.4)\n",
      "Requirement already satisfied: scipy in /Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages (from tabpy) (1.16.1)\n",
      "Collecting simplejson (from tabpy)\n",
      "  Downloading simplejson-3.20.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: scikit-learn in /Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages (from tabpy) (1.6.1)\n",
      "Collecting textblob (from tabpy)\n",
      "  Downloading textblob-0.19.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: tornado in /Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages (from tabpy) (6.5.1)\n",
      "Collecting twisted (from tabpy)\n",
      "  Downloading twisted-25.5.0-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: urllib3 in /Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages (from tabpy) (2.5.0)\n",
      "Collecting pyarrow (from tabpy)\n",
      "  Using cached pyarrow-21.0.0-cp311-cp311-macosx_12_0_arm64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages (from requests->tabpy) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages (from requests->tabpy) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages (from requests->tabpy) (2025.8.3)\n",
      "Collecting attrs>=22.2.0 (from hypothesis->tabpy)\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting sortedcontainers<3.0.0,>=2.1.0 (from hypothesis->tabpy)\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema->tabpy)\n",
      "  Using cached jsonschema_specifications-2025.4.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema->tabpy)\n",
      "  Using cached referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema->tabpy)\n",
      "  Using cached rpds_py-0.26.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.2 kB)\n",
      "Collecting click (from nltk->tabpy)\n",
      "  Using cached click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: joblib in /Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages (from nltk->tabpy) (1.5.1)\n",
      "Collecting regex>=2021.8.3 (from nltk->tabpy)\n",
      "  Downloading regex-2025.7.34-cp311-cp311-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tqdm (from nltk->tabpy)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages (from pandas->tabpy) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages (from pandas->tabpy) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages (from pandas->tabpy) (2025.2)\n",
      "Collecting cryptography<46,>=41.0.5 (from pyopenssl->tabpy)\n",
      "  Downloading cryptography-45.0.6-cp311-abi3-macosx_10_9_universal2.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.9 in /Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages (from pyopenssl->tabpy) (4.14.1)\n",
      "Collecting iniconfig>=1 (from pytest->tabpy)\n",
      "  Downloading iniconfig-2.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: packaging>=20 in /Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages (from pytest->tabpy) (25.0)\n",
      "Collecting pluggy<2,>=1.5 (from pytest->tabpy)\n",
      "  Downloading pluggy-1.6.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: pygments>=2.7.2 in /Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages (from pytest->tabpy) (2.19.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages (from scikit-learn->tabpy) (3.6.0)\n",
      "Collecting automat>=24.8.0 (from twisted->tabpy)\n",
      "  Downloading automat-25.4.16-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting constantly>=15.1 (from twisted->tabpy)\n",
      "  Downloading constantly-23.10.4-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting hyperlink>=17.1.1 (from twisted->tabpy)\n",
      "  Downloading hyperlink-21.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting incremental>=24.7.0 (from twisted->tabpy)\n",
      "  Downloading incremental-24.7.2-py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting zope-interface>=5 (from twisted->tabpy)\n",
      "  Downloading zope.interface-7.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (44 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cffi>=1.14 (from cryptography<46,>=41.0.5->pyopenssl->tabpy)\n",
      "  Using cached cffi-1.17.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: setuptools>=61.0 in /Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages (from incremental>=24.7.0->twisted->tabpy) (65.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/Jiwon/Documents/GitHub/practical_project/wonv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->tabpy) (1.17.0)\n",
      "Collecting pycparser (from cffi>=1.14->cryptography<46,>=41.0.5->pyopenssl->tabpy)\n",
      "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Downloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading configparser-7.2.0-py3-none-any.whl (17 kB)\n",
      "Downloading coverage-7.10.2-cp311-cp311-macosx_11_0_arm64.whl (215 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.5/215.5 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading coveralls-4.0.1-py3-none-any.whl (13 kB)\n",
      "Downloading future-1.0.0-py3-none-any.whl (491 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.3/491.3 kB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading genson-1.3.0-py3-none-any.whl (21 kB)\n",
      "Downloading hypothesis-6.137.1-py3-none-any.whl (527 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.6/527.6 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached jsonschema-4.25.0-py3-none-any.whl (89 kB)\n",
      "Downloading mock-5.2.0-py3-none-any.whl (31 kB)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pyarrow-21.0.0-cp311-cp311-macosx_12_0_arm64.whl (31.2 MB)\n",
      "Downloading pyopenssl-25.1.0-py3-none-any.whl (56 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m576.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytest-8.4.1-py3-none-any.whl (365 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.5/365.5 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytest_cov-6.2.1-py3-none-any.whl (24 kB)\n",
      "Downloading simplejson-3.20.1-cp311-cp311-macosx_11_0_arm64.whl (74 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.8/74.8 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading textblob-0.19.0-py3-none-any.whl (624 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m624.3/624.3 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading twisted-25.5.0-py3-none-any.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Downloading automat-25.4.16-py3-none-any.whl (42 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading constantly-23.10.4-py3-none-any.whl (13 kB)\n",
      "Downloading cryptography-45.0.6-cp311-abi3-macosx_10_9_universal2.whl (7.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading hyperlink-21.0.0-py2.py3-none-any.whl (74 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.6/74.6 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading incremental-24.7.2-py3-none-any.whl (20 kB)\n",
      "Downloading iniconfig-2.1.0-py3-none-any.whl (6.0 kB)\n",
      "Using cached jsonschema_specifications-2025.4.1-py3-none-any.whl (18 kB)\n",
      "Downloading pluggy-1.6.0-py3-none-any.whl (20 kB)\n",
      "Using cached referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Downloading regex-2025.7.34-cp311-cp311-macosx_11_0_arm64.whl (285 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m285.9/285.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached rpds_py-0.26.0-cp311-cp311-macosx_11_0_arm64.whl (358 kB)\n",
      "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Downloading zope.interface-7.2-cp311-cp311-macosx_11_0_arm64.whl (209 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.3/209.3 kB\u001b[0m \u001b[31m158.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached click-8.2.1-py3-none-any.whl (102 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached cffi-1.17.1-cp311-cp311-macosx_11_0_arm64.whl (178 kB)\n",
      "Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Building wheels for collected packages: tabpy, docopt\n",
      "  Building wheel for tabpy (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for tabpy: filename=tabpy-2.13.0-py2.py3-none-any.whl size=122730 sha256=277a93ea53c4ed2908d75d199233d5fbcaa4698e92740b56fe1fc88232a0f134\n",
      "  Stored in directory: /Users/Jiwon/Library/Caches/pip/wheels/a0/50/f8/33c9a226175b88e881cd2088d96ce2c4bfe62fab092bddc6a5\n",
      "  Building wheel for docopt (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13783 sha256=06e070753f45c72bcf23e21887339787d7b4326168dd45bf8a00227580c960e3\n",
      "  Stored in directory: /Users/Jiwon/Library/Caches/pip/wheels/1a/b0/8c/4b75c4116c31f83c8f9f047231251e13cc74481cca4a78a9ce\n",
      "Successfully built tabpy docopt\n",
      "Installing collected packages: sortedcontainers, genson, docopt, zope-interface, tqdm, simplejson, rpds-py, regex, pycparser, pyarrow, pluggy, mock, iniconfig, incremental, hyperlink, future, coverage, constantly, configparser, cloudpickle, click, automat, attrs, twisted, referencing, pytest, nltk, hypothesis, cffi, textblob, pytest-cov, jsonschema-specifications, cryptography, coveralls, pyopenssl, jsonschema, tabpy\n",
      "Successfully installed attrs-25.3.0 automat-25.4.16 cffi-1.17.1 click-8.2.1 cloudpickle-3.1.1 configparser-7.2.0 constantly-23.10.4 coverage-7.10.2 coveralls-4.0.1 cryptography-45.0.6 docopt-0.6.2 future-1.0.0 genson-1.3.0 hyperlink-21.0.0 hypothesis-6.137.1 incremental-24.7.2 iniconfig-2.1.0 jsonschema-4.25.0 jsonschema-specifications-2025.4.1 mock-5.2.0 nltk-3.9.1 pluggy-1.6.0 pyarrow-21.0.0 pycparser-2.22 pyopenssl-25.1.0 pytest-8.4.1 pytest-cov-6.2.1 referencing-0.36.2 regex-2025.7.34 rpds-py-0.26.0 simplejson-3.20.1 sortedcontainers-2.4.0 tabpy-2.13.0 textblob-0.19.0 tqdm-4.67.1 twisted-25.5.0 zope-interface-7.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tabpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8886117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000228 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 974\n",
      "[LightGBM] [Info] Number of data points in the train set: 16840, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 11.778979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(55842) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(55843) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(55844) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(55845) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(55846) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(55847) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(55848) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(55849) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001516 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 974\n",
      "[LightGBM] [Info] Number of data points in the train set: 16840, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 11.778979\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012641 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 964\n",
      "[LightGBM] [Info] Total Bins 968\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010960 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 971\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 14\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 14\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 14\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011801 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 972\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 11.775683\n",
      "[LightGBM] [Info] Start training from score 11.787485\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006005 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 968\n",
      "[LightGBM] [Info] Start training from score 11.769151\n",
      "[LightGBM] [Info] Number of data points in the train set: 13472, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 11.764326\n",
      "[LightGBM] [Info] Start training from score 11.798248\n",
      "✅ 모델 파이프라인을 milk_yield_pipeline.pkl에 저장 완료\n"
     ]
    }
   ],
   "source": [
    "# save_model.py\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor, VotingRegressor, StackingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# 1) 데이터 로드 (df_clean이 이미 정의되어 있다고 가정)\n",
    "# df_clean = pd.read_csv(\"your_clean_data.csv\")\n",
    "\n",
    "# 2) 타깃 & 피처 분리\n",
    "y = df_clean['착유량']\n",
    "X = df_clean[[\n",
    "    \"개체번호\",\"공기흐름_비율\",\"P/F_ratio\",\"개체별_착유일수\",\n",
    "    \"측정일\",\"농장아이디\",\"착유시간\",\"착유회차\",\n",
    "    \"착유시간대\",\"온도\",\"나이\",\"혈액흐름\",\n",
    "    \"개체별_일별착유횟수\",\"유지방\",\"유단백\"\n",
    "]]\n",
    "\n",
    "# 3) 범주형 인코딩\n",
    "cat_feats = ['농장아이디','개체번호']\n",
    "te = TargetEncoder(cols=cat_feats)\n",
    "X_enc = te.fit_transform(X, y)\n",
    "\n",
    "# 4) Train/Test split (테스트용)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_enc, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 5) 개별 모델 정의 & 학습\n",
    "rf  = RandomForestRegressor(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "xgb = XGBRegressor(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "lgb = LGBMRegressor(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Voting 앙상블\n",
    "voting = VotingRegressor([\n",
    "    ('rf', rf), ('xgb', xgb), ('lgb', lgb)\n",
    "])\n",
    "voting.fit(X_train, y_train)\n",
    "\n",
    "# Stacking 앙상블 (메타: Ridge)\n",
    "stack = StackingRegressor(\n",
    "    estimators=[('rf', rf), ('xgb', xgb), ('lgb', lgb)],\n",
    "    final_estimator=Ridge(),\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "stack.fit(X_train, y_train)\n",
    "\n",
    "# 6) Encoder + 앙상블을 파이프라인으로 묶기\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipe = Pipeline([\n",
    "    ('te', te),\n",
    "    ('voting', voting)        # 혹은 ('stack', stack)으로 바꿔 사용\n",
    "])\n",
    "\n",
    "# 7) Pickle로 저장\n",
    "with open('milk_yield_pipeline.pkl', 'wb') as f:\n",
    "    pickle.dump(pipe, f)\n",
    "\n",
    "print(\"✅ 모델 파이프라인을 milk_yield_pipeline.pkl에 저장 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1de97bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ TabPy에 ‘milk_yield_ensemble’ 모델 배포 완료\n"
     ]
    }
   ],
   "source": [
    "# deploy_to_tabpy.py\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tabpy.tabpy_tools.client import Client\n",
    "\n",
    "# 1) TabPy 서버 URL\n",
    "TABPY_URL = \"http://localhost:9004/\"\n",
    "\n",
    "# 2) 저장해 둔 파이프라인 불러오기\n",
    "with open('milk_yield_pipeline.pkl', 'rb') as f:\n",
    "    pipeline = pickle.load(f)\n",
    "\n",
    "# 3) TabPy 클라이언트 생성\n",
    "client = Client(TABPY_URL)\n",
    "\n",
    "# 4) 예측 함수 정의\n",
    "def predict_milk_yield(*args):\n",
    "    \"\"\"\n",
    "    args 순서는 아래 FEATURE_ORDER와 동일해야 합니다.\n",
    "    \"\"\"\n",
    "    X = np.array(args).reshape(1, -1)\n",
    "    return float(pipeline.predict(X)[0])\n",
    "\n",
    "# 5) TabPy에 배포\n",
    "#    첫 번째 positional: 서비스명\n",
    "#    두 번째 positional: 함수\n",
    "client.deploy(\n",
    "    \"milk_yield_ensemble\",    # Tableau에서 호출할 이름\n",
    "    predict_milk_yield,\n",
    "    description=\"TargetEncoder+VotingEnsemble 기반 착유량 예측\",\n",
    "    override=True\n",
    ")\n",
    "\n",
    "print(\"✅ TabPy에 ‘milk_yield_ensemble’ 모델 배포 완료\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a6cbc257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>농장아이디</th>\n",
       "      <th>개체번호</th>\n",
       "      <th>착유량</th>\n",
       "      <th>착유시작일시</th>\n",
       "      <th>착유종료일시</th>\n",
       "      <th>착유회차</th>\n",
       "      <th>전도도</th>\n",
       "      <th>혈액흐름</th>\n",
       "      <th>온도</th>\n",
       "      <th>유지방</th>\n",
       "      <th>...</th>\n",
       "      <th>측정일</th>\n",
       "      <th>개체별_일일착유량</th>\n",
       "      <th>개체별_착유일수</th>\n",
       "      <th>착유시간대</th>\n",
       "      <th>P/F_ratio</th>\n",
       "      <th>착유효율</th>\n",
       "      <th>개체별_전도도율</th>\n",
       "      <th>공기흐름_비율</th>\n",
       "      <th>개체별_일별착유횟수</th>\n",
       "      <th>comp_pca</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20278</td>\n",
       "      <td>20130816010079</td>\n",
       "      <td>16</td>\n",
       "      <td>2021-09-01 06:52:00</td>\n",
       "      <td>2021-09-01 07:04:00</td>\n",
       "      <td>1</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0</td>\n",
       "      <td>39.9</td>\n",
       "      <td>4.1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>0.804878</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>7.042857</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.378273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20278</td>\n",
       "      <td>20130816010079</td>\n",
       "      <td>17</td>\n",
       "      <td>2021-09-01 17:02:00</td>\n",
       "      <td>2021-09-01 17:11:00</td>\n",
       "      <td>2</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0</td>\n",
       "      <td>40.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>1.888889</td>\n",
       "      <td>7.042857</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>2</td>\n",
       "      <td>0.363437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20278</td>\n",
       "      <td>20130816010079</td>\n",
       "      <td>14</td>\n",
       "      <td>2021-09-02 01:41:00</td>\n",
       "      <td>2021-09-02 01:51:00</td>\n",
       "      <td>1</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0</td>\n",
       "      <td>39.9</td>\n",
       "      <td>4.8</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>7.042857</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>3</td>\n",
       "      <td>1.010125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20278</td>\n",
       "      <td>20130816010079</td>\n",
       "      <td>10</td>\n",
       "      <td>2021-09-02 07:28:00</td>\n",
       "      <td>2021-09-02 07:36:00</td>\n",
       "      <td>2</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0</td>\n",
       "      <td>39.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>7.042857</td>\n",
       "      <td>0.212500</td>\n",
       "      <td>3</td>\n",
       "      <td>1.200171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20278</td>\n",
       "      <td>20130816010079</td>\n",
       "      <td>11</td>\n",
       "      <td>2021-09-02 14:33:00</td>\n",
       "      <td>2021-09-02 14:45:00</td>\n",
       "      <td>3</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>7.042857</td>\n",
       "      <td>0.108333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.553483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   농장아이디            개체번호  착유량              착유시작일시              착유종료일시  착유회차  \\\n",
       "0  20278  20130816010079   16 2021-09-01 06:52:00 2021-09-01 07:04:00     1   \n",
       "1  20278  20130816010079   17 2021-09-01 17:02:00 2021-09-01 17:11:00     2   \n",
       "2  20278  20130816010079   14 2021-09-02 01:41:00 2021-09-02 01:51:00     1   \n",
       "3  20278  20130816010079   10 2021-09-02 07:28:00 2021-09-02 07:36:00     2   \n",
       "4  20278  20130816010079   11 2021-09-02 14:33:00 2021-09-02 14:45:00     3   \n",
       "\n",
       "   전도도  혈액흐름    온도  유지방  ...  측정일  개체별_일일착유량  개체별_착유일수  착유시간대  P/F_ratio  \\\n",
       "0  7.1     0  39.9  4.1  ...    1         33        26      2   0.804878   \n",
       "1  6.8     0  40.2  4.5  ...    1         33        26      3   0.711111   \n",
       "2  6.8     0  39.9  4.8  ...    2         35        26      1   0.645833   \n",
       "3  6.8     0  39.6  5.0  ...    2         35        26      2   0.620000   \n",
       "4  6.8     0  40.0  4.7  ...    2         35        26      3   0.680851   \n",
       "\n",
       "       착유효율  개체별_전도도율   공기흐름_비율  개체별_일별착유횟수  comp_pca  \n",
       "0  1.333333  7.042857  0.125000           2 -0.378273  \n",
       "1  1.888889  7.042857  0.233333           2  0.363437  \n",
       "2  1.400000  7.042857  0.190000           3  1.010125  \n",
       "3  1.250000  7.042857  0.212500           3  1.200171  \n",
       "4  0.916667  7.042857  0.108333           3  0.553483  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fe3f380c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_csv(\"clean_test.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e98bdf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wonv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
