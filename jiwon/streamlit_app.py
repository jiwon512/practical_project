import streamlit as st
import pandas as pd
import numpy as np
import pickle
from datetime import datetime, timedelta
import plotly.express as px
import plotly.graph_objects as go
from sklearn.model_selection import train_test_split
from category_encoders import TargetEncoder
from sklearn.ensemble import RandomForestRegressor, VotingRegressor, StackingRegressor
from xgboost import XGBRegressor
from lightgbm import LGBMRegressor
from sklearn.linear_model import Ridge
from sklearn.pipeline import Pipeline

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ìŠ¤ë§ˆíŠ¸íŒœ ì°©ìœ ëŸ‰ ì˜ˆì¸¡ ì‹œìŠ¤í…œ",
    page_icon="ğŸ„",
    layout="wide"
)

# ì œëª©
st.title("ğŸ„ ìŠ¤ë§ˆíŠ¸íŒœ ì°©ìœ ëŸ‰ ì˜ˆì¸¡ ì‹œìŠ¤í…œ")
st.markdown("---")

@st.cache_data
def load_data():
    """ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬"""
    try:
        # ë°ì´í„° ë¡œë“œ (ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš© ê²½ë¡œ)
        df = pd.read_csv("../csv/ìŠ¤ë§ˆíŠ¸íŒœ_ìˆ˜ì •ë°ì´í„°.csv", encoding="cp949")
        
        # ë‚ ì§œ ì»¬ëŸ¼ ë³€í™˜
        date_cols = ['ì°©ìœ ì‹œì‘ì¼ì‹œ', 'ì°©ìœ ì¢…ë£Œì¼ì‹œ']
        for c in date_cols:
            df[c] = pd.to_datetime(df[c], errors='coerce')
        
        # ì°©ìœ ì‹œê°„ ê³„ì‚°
        df['ì°©ìœ ì‹œê°„'] = (df['ì°©ìœ ì¢…ë£Œì¼ì‹œ'] - df['ì°©ìœ ì‹œì‘ì¼ì‹œ']).dt.total_seconds() / 60
        
        # ì°©ìœ ì‹œê°„ëŒ€ êµ¬ë¶„
        df['ì°©ìœ ì‹œê°„ëŒ€'] = df['ì°©ìœ ì‹œì‘ì¼ì‹œ'].dt.hour
        df['ì°©ìœ ì‹œê°„ëŒ€'] = pd.cut(
            df['ì°©ìœ ì‹œê°„ëŒ€'],
            bins=[0,6,12,18,24],
            right=False,
            labels=[1,2,3,4]
        ).cat.codes + 1
        
        # íŒŒìƒë³€ìˆ˜ ìƒì„±
        df["P/F_ratio"] = df["ìœ ë‹¨ë°±"] / df["ìœ ì§€ë°©"]
        df["ì°©ìœ íš¨ìœ¨"] = df["ì°©ìœ ëŸ‰"] / df["ì°©ìœ ì‹œê°„"]
        df["ê°œì²´ë³„_ì „ë„ë„ìœ¨"] = df.groupby("ê°œì²´ë²ˆí˜¸")["ì „ë„ë„"].transform("mean")
        df['ê³µê¸°íë¦„_ë¹„ìœ¨'] = df['ê³µê¸°íë¦„'] / df['ì°©ìœ ì‹œê°„']
        
        # ì¸¡ì •ì¼ ì¶”ì¶œ (ìˆ«ìë¡œ ë³€í™˜)
        df['ì¸¡ì •ì¼'] = df['ì°©ìœ ì‹œì‘ì¼ì‹œ'].dt.strftime('%Y%m%d').astype(int)
        
        # ê°œì²´ë³„ ì°©ìœ ì¼ìˆ˜
        df['ê°œì²´ë³„_ì°©ìœ ì¼ìˆ˜'] = df.groupby('ê°œì²´ë²ˆí˜¸')['ì¸¡ì •ì¼'].transform('nunique')
        
        # ê°œì²´ë³„ ì¼ë³„ ì°©ìœ íšŸìˆ˜
        df['ê°œì²´ë³„_ì¼ë³„ì°©ìœ íšŸìˆ˜'] = df.groupby(['ê°œì²´ë²ˆí˜¸','ì¸¡ì •ì¼'])['ì°©ìœ íšŒì°¨'].transform('count')
        
        # ë‚˜ì´ ê³„ì‚° (ê°œì²´ë²ˆí˜¸ì—ì„œ ì¶”ì¶œ)
        df['ë‚˜ì´'] = df['ê°œì²´ë²ˆí˜¸'].astype(str).str[4:6].astype(int)
        
        # ì»¬ëŸ¼ëª… ì •ë¦¬
        df.columns = [c.strip().replace(" ", "_") for c in df.columns]
        
        # ì´ìƒì¹˜ ì œê±°
        outlier_cols = ['ì°©ìœ ëŸ‰', 'ì°©ìœ íšŒì°¨', 'ì „ë„ë„', 'ì˜¨ë„', 'ìœ ì§€ë°©', 'ìœ ë‹¨ë°±', 'ê³µê¸°íë¦„', 'ì°©ìœ ì‹œê°„']
        bounds = {}
        for col in outlier_cols:
            Q1 = df[col].quantile(0.25)
            Q3 = df[col].quantile(0.75)
            IQR = Q3 - Q1
            lower = Q1 - 3 * IQR
            upper = Q3 + 3 * IQR
            bounds[col] = (lower, upper)
        
        mask = pd.Series(True, index=df.index)
        for col, (lower, upper) in bounds.items():
            mask &= df[col].between(lower, upper)
        
        df_clean = df.loc[mask].copy()
        
        return df_clean
        
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {e}")
        return None

@st.cache_resource
def train_model(df_clean):
    """ëª¨ë¸ í•™ìŠµ"""
    try:
        # íƒ€ê²Ÿê³¼ í”¼ì²˜ ë¶„ë¦¬
        y = df_clean['ì°©ìœ ëŸ‰']
        X = df_clean[[
            "ê°œì²´ë²ˆí˜¸","ê³µê¸°íë¦„_ë¹„ìœ¨","P/F_ratio","ê°œì²´ë³„_ì°©ìœ ì¼ìˆ˜",
            "ì¸¡ì •ì¼","ë†ì¥ì•„ì´ë””","ì°©ìœ ì‹œê°„","ì°©ìœ íšŒì°¨",
            "ì°©ìœ ì‹œê°„ëŒ€","ì˜¨ë„","ë‚˜ì´","í˜ˆì•¡íë¦„",
            "ê°œì²´ë³„_ì¼ë³„ì°©ìœ íšŸìˆ˜","ìœ ì§€ë°©","ìœ ë‹¨ë°±"
        ]]
        
        # ë²”ì£¼í˜• ì¸ì½”ë”© (í˜ˆì•¡íë¦„ë„ í¬í•¨)
        cat_feats = ['ë†ì¥ì•„ì´ë””','ê°œì²´ë²ˆí˜¸','í˜ˆì•¡íë¦„']
        te = TargetEncoder(cols=cat_feats)
        X_enc = te.fit_transform(X, y)
        
        # Train/Test split
        X_train, X_test, y_train, y_test = train_test_split(
            X_enc, y, test_size=0.2, random_state=42
        )
        
        # ê°œë³„ ëª¨ë¸ ì •ì˜
        rf = RandomForestRegressor(n_estimators=200, random_state=42, n_jobs=-1)
        xgb = XGBRegressor(n_estimators=200, random_state=42, n_jobs=-1)
        lgb = LGBMRegressor(n_estimators=200, random_state=42, n_jobs=-1)
        
        # Voting ì•™ìƒë¸”
        voting = VotingRegressor([('rf', rf), ('xgb', xgb), ('lgb', lgb)])
        voting.fit(X_train, y_train)
        
        # Stacking ì•™ìƒë¸”
        stack = StackingRegressor(
            estimators=[('rf', rf), ('xgb', xgb), ('lgb', lgb)],
            final_estimator=Ridge(),
            cv=5,
            n_jobs=-1
        )
        stack.fit(X_train, y_train)
        
        # íŒŒì´í”„ë¼ì¸ ìƒì„±
        pipeline = Pipeline([
            ('te', te),
            ('stack', stack)
        ])
        
        return pipeline, X_train.columns.tolist()
        
    except Exception as e:
        st.error(f"ëª¨ë¸ í•™ìŠµ ì˜¤ë¥˜: {e}")
        return None, None

def predict_farm_yield(pipeline, farm_id, date, feature_columns):
    """ë†ì¥ë³„ ì°©ìœ ëŸ‰ ì˜ˆì¸¡"""
    try:
        # ë‚ ì§œë¥¼ ìˆ«ì í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (YYYYMMDD)
        date_int = int(date.replace('-', ''))
        
        # ê¸°ë³¸ê°’ìœ¼ë¡œ ì˜ˆì¸¡ ë°ì´í„° ìƒì„±
        sample_data = pd.DataFrame({
            'ê°œì²´ë²ˆí˜¸': [20278],  # ê¸°ë³¸ ê°œì²´ë²ˆí˜¸
            'ê³µê¸°íë¦„_ë¹„ìœ¨': [0.5],
            'P/F_ratio': [3.0],
            'ê°œì²´ë³„_ì°©ìœ ì¼ìˆ˜': [30],
            'ì¸¡ì •ì¼': [date_int],
            'ë†ì¥ì•„ì´ë””': [farm_id],
            'ì°©ìœ ì‹œê°„': [10],
            'ì°©ìœ íšŒì°¨': [1],
            'ì°©ìœ ì‹œê°„ëŒ€': [1],
            'ì˜¨ë„': [39.0],
            'ë‚˜ì´': [8],
            'í˜ˆì•¡íë¦„': ['N'],  # TargetEncoderë¡œ ì¸ì½”ë”©ë¨
            'ê°œì²´ë³„_ì¼ë³„ì°©ìœ íšŸìˆ˜': [2],
            'ìœ ì§€ë°©': [3.5],
            'ìœ ë‹¨ë°±': [3.2]
        })
        
        # ì˜ˆì¸¡
        prediction = pipeline.predict(sample_data)[0]
        return prediction
        
    except Exception as e:
        st.error(f"ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")
        return None

def predict_individual_yield(pipeline, individual_data):
    """ê°œì²´ë³„ ì°©ìœ ëŸ‰ ì˜ˆì¸¡"""
    try:
        prediction = pipeline.predict(individual_data)[0]
        return prediction
    except Exception as e:
        st.error(f"ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")
        return None

def main():
    # ë°ì´í„° ë¡œë“œ
    with st.spinner("ë°ì´í„°ë¥¼ ë¡œë“œí•˜ëŠ” ì¤‘..."):
        df_clean = load_data()
    
    if df_clean is None:
        st.error("ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ëª¨ë¸ í•™ìŠµ
    with st.spinner("ëª¨ë¸ì„ í•™ìŠµí•˜ëŠ” ì¤‘..."):
        pipeline, feature_columns = train_model(df_clean)
    
    if pipeline is None:
        st.error("ëª¨ë¸ì„ í•™ìŠµí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ì‚¬ì´ë“œë°”
    st.sidebar.title("ğŸ“Š ì˜ˆì¸¡ ì˜µì…˜")
    prediction_type = st.sidebar.selectbox(
        "ì˜ˆì¸¡ ìœ í˜• ì„ íƒ",
        ["ë†ì¥ë³„ ì˜ˆì¸¡", "ê°œì²´ë³„ ì˜ˆì¸¡"]
    )
    
    if prediction_type == "ë†ì¥ë³„ ì˜ˆì¸¡":
        st.header("ğŸ­ ë†ì¥ë³„ ì°©ìœ ëŸ‰ ì˜ˆì¸¡")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # ë†ì¥ ì„ íƒ
            farm_ids = sorted(df_clean['ë†ì¥ì•„ì´ë””'].unique())
            selected_farm = st.selectbox("ë†ì¥ ì„ íƒ", farm_ids)
            
            # ì˜ˆì¸¡ ê¸°ê°„ ì„ íƒ
            prediction_period = st.selectbox(
                "ì˜ˆì¸¡ ê¸°ê°„",
                ["ë‹¤ìŒì£¼", "ë‹¤ìŒë‹¬"]
            )
        
        with col2:
            # ì˜ˆì¸¡ ë‚ ì§œ ì„¤ì •
            today = datetime.now()
            if prediction_period == "ë‹¤ìŒì£¼":
                target_date = today + timedelta(days=7)
            else:
                target_date = today + timedelta(days=30)
            
            st.write(f"**ì˜ˆì¸¡ ë‚ ì§œ:** {target_date.strftime('%Y-%m-%d')}")
        
        # ì˜ˆì¸¡ ì‹¤í–‰
        if st.button("ğŸš€ ì˜ˆì¸¡ ì‹¤í–‰", type="primary"):
            with st.spinner("ì˜ˆì¸¡ ì¤‘..."):
                prediction = predict_farm_yield(
                    pipeline, selected_farm, 
                    target_date.strftime('%Y-%m-%d'), 
                    feature_columns
                )
                
                if prediction is not None:
                    # ê²°ê³¼ í‘œì‹œ
                    st.success("âœ… ì˜ˆì¸¡ ì™„ë£Œ!")
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric(
                            label="ì˜ˆì¸¡ ì°©ìœ ëŸ‰",
                            value=f"{prediction:.1f}L",
                            delta=f"{prediction - 12:.1f}L"  # í‰ê·  ëŒ€ë¹„
                        )
                    
                    with col2:
                        st.metric(
                            label="ì˜ˆì¸¡ ê¸°ê°„",
                            value=prediction_period
                        )
                    
                    with col3:
                        st.metric(
                            label="ë†ì¥ ID",
                            value=selected_farm
                        )
                    
                    # ë†ì¥ë³„ í†µê³„ ì •ë³´
                    farm_stats = df_clean[df_clean['ë†ì¥ì•„ì´ë””'] == selected_farm]
                    
                    if not farm_stats.empty:
                        st.subheader("ğŸ“ˆ ë†ì¥ í†µê³„ ì •ë³´")
                        
                        col1, col2, col3, col4 = st.columns(4)
                        with col1:
                            st.metric("í‰ê·  ì°©ìœ ëŸ‰", f"{farm_stats['ì°©ìœ ëŸ‰'].mean():.1f}L")
                        with col2:
                            st.metric("ê°œì²´ ìˆ˜", len(farm_stats['ê°œì²´ë²ˆí˜¸'].unique()))
                        with col3:
                            st.metric("ì´ ì°©ìœ  íšŸìˆ˜", len(farm_stats))
                        with col4:
                            st.metric("í‰ê·  ì°©ìœ ì‹œê°„", f"{farm_stats['ì°©ìœ ì‹œê°„'].mean():.1f}ë¶„")
                        
                        # ì°©ìœ ëŸ‰ ë¶„í¬ ì°¨íŠ¸
                        fig = px.histogram(
                            farm_stats, 
                            x='ì°©ìœ ëŸ‰', 
                            nbins=20,
                            title=f"ë†ì¥ {selected_farm} ì°©ìœ ëŸ‰ ë¶„í¬"
                        )
                        st.plotly_chart(fig, use_container_width=True)
    
    else:  # ê°œì²´ë³„ ì˜ˆì¸¡
        st.header("ğŸ„ ê°œì²´ë³„ ì°©ìœ ëŸ‰ ì˜ˆì¸¡")
        
        # ê°œì²´ ì„ íƒ
        farm_ids = sorted(df_clean['ë†ì¥ì•„ì´ë””'].unique())
        selected_farm = st.selectbox("ë†ì¥ ì„ íƒ", farm_ids)
        
        # ì„ íƒëœ ë†ì¥ì˜ ê°œì²´ë“¤
        farm_individuals = df_clean[df_clean['ë†ì¥ì•„ì´ë””'] == selected_farm]['ê°œì²´ë²ˆí˜¸'].unique()
        selected_individual = st.selectbox("ê°œì²´ ì„ íƒ", sorted(farm_individuals))
        
        # ê°œì²´ ì •ë³´ í‘œì‹œ
        individual_data = df_clean[df_clean['ê°œì²´ë²ˆí˜¸'] == selected_individual]
        
        if not individual_data.empty:
            st.subheader("ğŸ“‹ ê°œì²´ ì •ë³´")
            
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("í‰ê·  ì°©ìœ ëŸ‰", f"{individual_data['ì°©ìœ ëŸ‰'].mean():.1f}L")
            with col2:
                st.metric("ì´ ì°©ìœ  íšŸìˆ˜", len(individual_data))
            with col3:
                st.metric("í‰ê·  ì°©ìœ ì‹œê°„", f"{individual_data['ì°©ìœ ì‹œê°„'].mean():.1f}ë¶„")
            with col4:
                st.metric("ë‚˜ì´", f"{individual_data['ë‚˜ì´'].iloc[0]}ì„¸")
            
            # ê°œì²´ë³„ ì°©ìœ ëŸ‰ ì¶”ì´
            fig = px.line(
                individual_data.sort_values('ì°©ìœ ì‹œì‘ì¼ì‹œ'),
                x='ì°©ìœ ì‹œì‘ì¼ì‹œ',
                y='ì°©ìœ ëŸ‰',
                title=f"ê°œì²´ {selected_individual} ì°©ìœ ëŸ‰ ì¶”ì´"
            )
            st.plotly_chart(fig, use_container_width=True)
            
            # ì˜ˆì¸¡ ì‹¤í–‰
            if st.button("ğŸš€ ê°œì²´ë³„ ì˜ˆì¸¡ ì‹¤í–‰", type="primary"):
                with st.spinner("ì˜ˆì¸¡ ì¤‘..."):
                    # ìµœê·¼ ë°ì´í„°ë¡œ ì˜ˆì¸¡
                    recent_data = individual_data.iloc[-1:].copy()
                    prediction = predict_individual_yield(pipeline, recent_data)
                    
                    if prediction is not None:
                        st.success("âœ… ì˜ˆì¸¡ ì™„ë£Œ!")
                        
                        col1, col2 = st.columns(2)
                        with col1:
                            st.metric(
                                label="ë‹¤ìŒ ì°©ìœ  ì˜ˆì¸¡ëŸ‰",
                                value=f"{prediction:.1f}L",
                                delta=f"{prediction - individual_data['ì°©ìœ ëŸ‰'].mean():.1f}L"
                            )
                        
                        with col2:
                            st.metric(
                                label="ê°œì²´ ë²ˆí˜¸",
                                value=selected_individual
                            )
    
    # ëª¨ë¸ ì •ë³´
    st.sidebar.markdown("---")
    st.sidebar.subheader("ğŸ¤– ëª¨ë¸ ì •ë³´")
    st.sidebar.info("""
    **ìŠ¤íƒí‚¹ ì•™ìƒë¸” ëª¨ë¸**
    - Random Forest
    - XGBoost  
    - LightGBM
    - ë©”íƒ€ëª¨ë¸: Ridge
    """)
    
    # ë°ì´í„° ì •ë³´
    st.sidebar.subheader("ğŸ“Š ë°ì´í„° ì •ë³´")
    st.sidebar.info(f"""
    **ì´ ë°ì´í„°**: {len(df_clean):,}ê°œ
    **ë†ì¥ ìˆ˜**: {len(df_clean['ë†ì¥ì•„ì´ë””'].unique())}ê°œ
    **ê°œì²´ ìˆ˜**: {len(df_clean['ê°œì²´ë²ˆí˜¸'].unique())}ê°œ
    **ê¸°ê°„**: {df_clean['ì°©ìœ ì‹œì‘ì¼ì‹œ'].min().strftime('%Y-%m-%d')} ~ {df_clean['ì°©ìœ ì‹œì‘ì¼ì‹œ'].max().strftime('%Y-%m-%d')}
    """)

if __name__ == "__main__":
    main() 